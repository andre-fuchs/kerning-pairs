Unter Universalien der Musikwahrnehmung werden Elemente der Musikwahrnehmung und -verarbeitung verstanden, die als angeboren, d. h. kulturunabhängig, betrachtet werden.
Vielfach wird die Ansicht vertreten, Musik sei eine universale Ausdrucksform. Das impliziert die Annahme, dass Musik universale Merkmale besitzt, also Merkmale, die nahezu allen musikalischen Systemen auf der Welt gemeinsam sind, und dass es biologische Bedingungen für die Verarbeitung von Musik gibt. Seit der Antike ist umstritten, ob es sich bei Universalien um Konstruktionen handelt, die nicht wirklich sind, oder ob sie als Tatsachen anerkannt werden können. Dieses Problem wird Universalienproblem genannt.
Von einem universalen Merkmal wird gesprochen, wenn das Merkmal nicht gelernt wird, sondern spontan erscheint, weil es latent in allen normalen Personen vorhanden, also angeboren ist (Dissanayake, 2001). Aus dieser Perspektive ist Musik keine universale Sprache, sondern die Universalien der Musikwahrnehmung und -verarbeitung umschreiben vielmehr Bedingungen für die Ausprägung der Merkmale der Musik verschiedener Kulturen.
Musikwahrnehmung beruht auf einer Reihe von unterschiedlichen Einflüssen, bei denen einige nahezu universell gelten, andere dagegen von persönlichen oder gruppenspezifischen Eigenschaften und Einstellungen abhängig sind:
Physikalische Einflüsse, d. h. das physikalische Schallsignal und die Art der Weiterleitung zum Gehör, sowie physikalische Rahmenbedingungen und Gesetzmäßigkeiten (z. B. Unschärferelation zwischen Frequenz- und Zeitauflösung). Diese Einflüsse sind universell gültig.
Anatomische und physiologische Einflüsse, z. B. Aufbau und Funktion von Außenohr, Mittelohr und Innenohr, Eigenschaften und Verhalten von Nervenzellen, „grundlegende“ Struktur und Verschaltung des Gehirns. Diese Einflüsse sind angeboren und im Allgemeinen für alle Menschen gültig. Ausnahmen kann es bei Menschen geben, bei denen das Gehör geschädigt ist oder bei angeborenen anatomischen Abweichungen. Für Tiere gelten diese Einflüsse nicht oder in anderer Form.
Frühkindliche Einflüsse. Um Sprache verstehen zu können, muss ein Kleinkind lernen, die Fülle von Nervenimpulsen, die das Innenohr und die dahinter liegenden Gehirnareale liefern, zu analysieren, um auf diese Weise die Muster von sprachrelevanten Lauten zu erkennen. Die dazu gelernten Analysetechniken bilden die Grundlage des Hörens und werden für die Musikwahrnehmung genutzt. Einige grundlegende Sprachkomponenten werden von den meisten Kulturen verwendet (stimmhafte und stimmlose Laute, Tonhöhen- und Lautstärkeveränderungen), sodass einige Grundzüge des Hörens sicherlich kulturübergreifend sind. Kulturelle Unterschiede kann es in Details geben.
Erkennendes Hören. Später werden Hörerfahrungen gesammelt, die zur Einordnung und Bewertung des Gehörten dienen. Dazu zählen z. B. die Herausbildung des persönlichen Geschmacks oder die Verknüpfung von Hörereignissen mit persönlichen Erfahrungen. Diese Einflüsse sind hochgradig individuell, bestenfalls noch gruppenspezifisch. Die dadurch geprägten Wahrnehmungen können nicht ohne Weiteres verallgemeinert werden. Individuen-übergreifende Aussagen lassen sich in diesem Bereich nur über statistische Verfahren erzielen. Für allgemeingültige Aussagen müssten möglichst heterogene Gruppen befragt werden.Als „universell“ können nur die Aussagen gelten, die in physikalischen Gegebenheiten, der menschlichen Anatomie, grundlegenden Signalverarbeitungmethoden des menschlichen Gehörs/Gehirns, sowie gruppen- und kulturübergreifenden Aspekten begründet sind.
Die Schallsignale, die auf das menschliche Ohr treffen, werden über das Außenohr, Mittelohr und Innenohr sowie durch die darauf folgende Signalverarbeitung im Gehirn gefiltert und vorverarbeitet, bevor sie wahrgenommen werden können. Die wahrgenommenen Eigenschaften eines Schalls, (z. B. die wahrgenommene  Tonhöhe, die Klangfarbe oder die Lautstärke) können auf Grund der Vorverarbeitung von den physikalisch gemessenen Eigenschaften des Schalls abweichen (z. B. die gemessene Grundfrequenz, der Schalldruckpegel oder dessen Spektrum). Beispiele: Bei Klavierklängen weicht z. B. die mit einem Frequenzmessgerät bestimmte Tonhöhe von der gehörten Tonhöhe ab (siehe auch Streckung). Eine Frequenzkomponente mit einem bestimmten Pegel kann einmal vom Gehör als sehr dominierend empfunden werden, ein andermal vom Gehör aber gar nicht mehr wahrgenommen werden (siehe auch Verdeckung).
Das heißt: Wollen Aussagen über die Wahrnehmung von Musiksignalen erzielt werden, reicht eine physikalische Analyse des Schalls nicht aus, es muss auch die Verarbeitung des Schalls im menschlichen Gehör berücksichtigt werden. Dazu sind psychoakustische Untersuchungen erforderlich.
Für Melodiestimmen werden häufig Musikinstrumente genutzt, die als  sogenannte „eindimensionale Schwinger“ beschrieben werden können. Zu den „eindimensionalen Schwingern“ zählen z. B. Saiteninstrumente (eine Saite schwingt auf und ab) oder Blasinstrumente (eine Luftsäule schwingt im Rohr hoch und herunter). Die Schwingungen und der abgestrahlte Schall sind  nahezu periodisch. Das Spektrum dieser periodischen Schwingungen  lässt sich in erster Näherung durch einen Grundton und dessen Obertöne beschreiben, wobei die Obertöne bei ganzzahligen Vielfachen der Grundfrequenz erzeugt werden. Die wahrgenommene Tonhöhe entspricht  dann der Tonhöhe des Grundtons.
Bei genauer Betrachtung stehen bei realen Musikinstrumenten Grundton und Obertöne nicht immer genau im Verhältnis kleiner ganzer Zahlen zueinander. Das führt dazu, dass sich Schwebungen entwickeln, die den Klang des Instruments „voller“ klingen lassen.
Bei realen Musikinstrumenten kommen zu den periodischen Schwingungen (z. B. der Saite oder Luftsäule) noch nicht-periodische Anteile bzw. Rauschanteile hinzu. Beispiele hierfür sind Anschlaggeräusche bei Saiteninstrumenten, Anblasgeräusche bei Blasinstrumenten und Orgelpfeifen. Diese Geräusche sind z. T. für den Klangeindruck prägend (der Klang einer Panflöte wäre ohne das Luftrauschen, das beim Anblasen entsteht, kaum wiederzuerkennen).
Bei vielen Musikinstrumenten ändert sich während des Erklingens eines Tons das Spektrum dieses Tons. So sind die spektralen Änderungen, die beim Einschwingen einer Saite oder der Luftsäule entstehen, oft prägend für den Klang eines Musikinstruments. Werden die ersten Zehntelsekunden jeweils ausgeblendet, lassen sich viele Musikinstrumente kaum noch identifizieren.
Zusätzlich kann sich die Frequenz eines Tons während des Erklingens ändern. Es gibt periodische Frequenzänderungen (z. B. Vibrato bei Flöten) oder nicht-periodische Frequenzänderungen (so ist z. B. beim Klavier beim Anschlag die Tonhöhe ein klein wenig höher als beim Ausklingen).
Rhythmusinstrumente (Trommeln, Pauken, Becken) und Glocken sind „zweidimensionale Schwinger“. Hier breiten sich Schwingungen auf einer Fläche aus (Trommelfell, Metallmantel). Es können sich unterschiedliche Schwingungszonen auf der schwingenden Fläche bilden. Die Gesamtschwingung und der abgestrahlte Schall sind nicht mehr periodisch. Entsprechend den unterschiedlichen angeregten Schwingungen enthält das Schallsignal nicht nur Frequenzen eines Grundtons und dessen ganzzahliger Vielfacher, sondern auch Frequenzanteile bei nicht-ganzzahligen Vielfachen. Die angeregten Frequenzen hängen dabei von Material, Form und Abmessungen des schwingenden Körpers ab. Weichen die Schwingungen nicht allzu stark von periodischen Schwingungen ab, oder ergibt sich ein ausgeprägtes spektrales Maximum bei einer Frequenz, so lassen sich diesen Klängen Tonhöhen zuordnen (z. B. bei Pauken und Glocken). Bei starken Abweichungen von periodischen Schwingungen ist eine Tonhöhenzuordnung nicht mehr möglich (z. B. bei Becken).
Analyse der  Schwingungsmechanik  Dabei wird versucht, das Schwingungsverhalten der einzelnen Bestandteile eines Musikinstruments zu messen oder zu modellieren (z. B. Schwingungsverhalten von Saiten, Verteilung von Schwingungen auf dem Klangkörper, Aufbau und Abbau der mechanischen Schwingungen).  Beispiel: Welche Schwingungen führen Saiten und Klangkörper einer Stradivari aus? Und was unterscheidet die Schwingungsverteilung auf dem Klangkörper einer Stradivari von der anderer Geigen?
Signaltheoretische Analyse  Dabei wird versucht, das akustische Signal, das ein Musikinstrument abgibt, genauer zu analysieren (z. B. Analyse der zeitlichen Verläufe von Spektrum, Pegel, Grundfrequenz).  Beispiel: Wie sieht das akustische Signal einer Stradivari aus? Wie entwickeln sich Grundfrequenz und Spektrum während eines Stradivari-Tons? Und worin besteht der Unterschied zu anderen Geigen?
Psychoakustische Analyse  Dabei wird versucht, die Wahrnehmungen zu analysieren, die ein Mensch beim Erklingen des Musikinstruments hat (z. B. wahrgenommene Tonhöhe, wahrgenommene Lautstärke, wahrgenommener Klang).  Beispiel: Wie wird der Klang einer Stradivari wahrgenommen? Welche Komponenten der Klangwahrnehmung sind wichtig für einen Stradivari-Klang? Und worin besteht der Unterschied in der Wahrnehmung im Vergleich zu andern Geigen?Da Musikinstrumente relativ komplexe Schwingungen durchführen können und auch die akustischen Signale von Musikinstrumenten nicht gerade einfache Strukturen aufweisen, kann die Analyse der Schwingungsmechanik oder des akustischen Signals eine mathematisch schon recht anspruchsvolle Aufgabe darstellen. Gleiches gilt für die Analyse der dadurch hervorgerufenen Wahrnehmungen des Menschen.
Dem Bereich, in dem Musik wahrgenommen werden kann, sind Grenzen durch die Hörfläche des Menschen gesetzt. Er kann Frequenzen zwischen 16 Hz und 20 kHz wahrnehmen. Im Wesentlichen beschränkt sich aber der für Musik verwendete Frequenzbereich auf Frequenzen zwischen 40 Hz und 10 kHz.
Das menschliche Gehör ist an der oberen und unteren Grenze des wahrnehmbaren Frequenzbereichs am unempfindlichsten und im Bereich zwischen 1000 und 5000 Hz, wo sich für das Sprachverstehen wichtige Frequenzbereiche befinden, am empfindlichsten.
Die Tonhöhenwahrnehmung und die Auflösung der Frequenzen im Hörbereich ist eng verbunden mit der Physiologie des Innenohres und des auditorischen Gehirns. Das Innenohr führt eine Frequenzanalyse des gehörten Signals durch, indem es unterschiedliche Frequenzen entlang der Haarzellenreihe im Cortischen Organ der Cochlea (Hörschnecke) herausfiltert. Dort befinden sich die Synapsen (Anschlussstellen) von Nervenzellen, die die Signale für die jeweiligen Frequenzen zur Verarbeitung an das Gehirn weiterleiten.
 Auswertung der Schwingungsperiode eines Tons (gestrichelte Linie im Bild rechts). Zur Auswertung der Schwingungsperiode werden die Erregungsmuster der Nervenzellen im auditorischen Mittelhirn (Colliculus inferior) auf Periodizitäten untersucht. Die wahrgenommene Tonhöhe entspricht dann der Grundfrequenz des Tons. Diese Auswertung ist nur möglich, so lange das Gehör der Periode des Signals noch folgen kann. Das ist, individuell unterschiedlich, bis zu Frequenzen zwischen 800 Hz (Ton g2) und 1600 Hz (Ton g3) der Fall.
Auswertung des Orts auf der Cochlea, an dem Nervenzellen angeregt werden. (gepunktete Linie im Bild rechts) Die wahrgenommene Tonhöhe ergibt sich dabei aus dem Abstand zwischen der Position maximaler Erregung der Haarzellenreihe und dem Ende der Cochlea. Der Ort auf der Cochlea wird zur Bestimmung der Tonhöhe angewandt, wenn das Gehör die Periode des Signals nicht mehr verfolgen kann, d. h. für Grundfrequenzen oberhalb von 800 bis 1600 Hz.Diese beiden Mechanismen haben unterschiedliche Auswirkungen auf die Wahrnehmung von Tonintervallen.
Wenn die Periode des Tons ausgewertet werden kann, entspricht die wahrgenommene Tonhöhe der Grundfrequenz des Tons. Bei einem Tonintervall ändert sich die Grundfrequenz der Töne um einen bestimmten Faktor und es wird derart unabhängig von der Tonlage als gleichartige Änderung der wahrgenommenen Tonhöhe empfunden. Das heißt: Tonintervalle und Melodien klingen in unterschiedlichen Tonlagen annähernd gleich.
Wird die wahrgenommene Tonhöhe über das Erregungsmaximum auf der Cochlea bestimmt, so wird der Zusammenhang zwischen wahrgenommener Tonhöhe und Frequenz des Tons nichtlinear. Die wahrgenommene Tonhöhe ändert sich bei gleichen Frequenzänderungen wesentlich weniger als beim ersten Mechanismus. Tonintervalle werden so oberhalb von 800 bis 1600 Hz kleiner empfunden als sie es von ihren Frequenzverhältnis sind. Das heißt: Melodien in sehr hohen Tonlagen (oberhalb von g2 bzw. g3) klingen anders als in niedrigen Tonlagen, und je höher die Tonlage jenseits dieser Grenze wird, als desto geringer werden Tonintervalle wahrgenommen.Bei der Wahrnehmung der Tonhöhe bei niedrigeren Frequenzen spielt die Zusammensetzung des Tons aus Grundton und Obertönen keine Rolle. Wichtig ist nur die Periode des Tons. So bleibt die Periode eines Tons und damit die wahrgenommene Tonhöhe selbst dann erhalten, wenn ein Ton nur aus Obertönen besteht und der Grundton fortgelassen wird (Residualton).
Die erreichbare Frequenz- und Tonhöhenauflösung hängt mit der Packungsdichte von Nervenzellanschlüssen in der Haarzellenreihe und mit der Möglichkeit des Gehirns, die Signale „Nervenzellen-genau“ zu verarbeiten, zusammen.
Bei niedrigen Frequenzen in der Nähe der unteren Grenzfrequenz des Gehörs entspricht eine musikalische Oktave weniger als einem Millimeter entlang der Haarzellenreihe. Hier ist die mögliche Tonhöhenauflösung relativ gering. Unterhalb von 500 Hz unterscheidet der Mensch etwa 270 verschiedene Tonhöhen mit konstantem Abstand von 1,8 Hz.
Mit zunehmender Frequenz vergrößert sich die Länge der Haarzellenreihe, die zur Auswertung einer Oktave zur Verfügung steht. Entsprechend steigt auch die mögliche Tonhöhenauflösung. Sie erreicht ab Frequenzen von 500 Hz mit einer Länge innerhalb der Haarzellenreihe von etwa 6 mm pro Oktave ihr Maximum.
Bei mittleren und höheren Frequenzen oberhalb von 500 Hz und bis etwa 3000 Hz bleibt die Länge der Haarzellenreihe pro Oktave und damit die erreichbare Tonhöhenauflösung in etwa konstant (etwa 6 mm pro Oktave). Von 500 Hz bis 15.000 Hz können etwa 350 logarithmische Tonabstände erkannt werden, geübte Musiker können Tonintervalle von etwa 1/33 Halbton (3 Cent) noch unterscheiden. Das entspricht einem Frequenzunterschied von 1 Hz bei 500 Hz.Aufgrund der erreichbaren Frequenzauflösung sind der Art und Weise, wie das Gehirn Tonhöhen kategorisiert, genauer, in wie viele Töne die Oktave unterteilt wird, Grenzen gesetzt. Es gibt keinen direkten Zusammenhang zwischen dem Unterscheidungsvermögen und der Kategorisierung der Tonhöhen in Tonleitern – diese Kategorien sind gröber und werden meistens in Ausrichtung an konsonanten Intervallen gelernt.
Die Physiologie und Verarbeitungsschritte des menschlichen Innenohres haben Auswirkungen auf die Wahrnehmung von Musikstücken. Ein wesentlicher Effekt des Innenohrs ist der sogenannte Maskierungseffekt: Werden einzelne Töne in einem Frequenzbereich vorgespielt, wo diese stärkemäßig überwiegen, so werden aufgrund der Mechanik des Innenohres nicht nur die Nervenzellen angeregt, die für diese Töne zuständig sind, sondern in erheblichem Maße noch Nervenzellen in der Umgebung. Da die wahrgenommene Lautstärke aber von der Gesamt-Erregung der Nervenzellen im Innenohr abhängt, führt das dazu, dass eine Melodiestimme lauter wahrgenommen wird, als sie physikalisch gesehen ist.
Musikanteile, die keinen Einzeltoncharakter haben (Begleitung in Akkorden, Rhythmusinstrumente) regen von ihrem Spektrum her eher einen breiten Frequenzbereich an, sodass hier kaum zusätzliche Nervenzellen aufgrund des Maskierungseffekts angeregt werden. Eine Anhebung der wahrgenommenen Lautstärke findet kaum statt.
Das trägt dazu bei, dass eine Melodiestimme innerhalb der Begleitung gut wahrgenommen werden kann, selbst wenn ihr Schallpegel nicht wesentlich höher ist als der der Begleitinstrumente.
Die Nervenzellen des Innenohres haben die Eigenschaft, dass ihre Erregung bei Dauerbelastung abnimmt. Nach kurzer Zeit der Ruhe regenerieren sie sich und geben bei erneuter Anregung besonders starke Signale ab.
Dieser Effekt führt zu einer Betonung des Rhythmus bei Musikstücken. Instrumente, die den Rhythmus tragen, erklingen oft nur für kurze Zeit und in Frequenzbereichen, in denen andere Musikstimmen gerade nicht präsent sind (z. B. tiefer Bassbereich bei einer großen Trommel, relativ obertonhaltiger Bereich bei Becken, aber auch: rhythmische Begleitung einer oder mehrerer Oktaven unter oder über der Melodiestimme).
In diesen Frequenzbereichen herrscht zwischen den Rhythmusschlägen relative Ruhe, sodass sich die für diese Frequenzen zuständigen Nervenzellen erholen können. Bei einem Rhythmusschlag erzeugen diese Nervenzellen dann ganz besonders starke Signale.
Das trägt dazu bei, dass Rhythmusinstrumente sehr gut wahrgenommen werden können, selbst wenn ihr Schallpegel nicht wesentlich höher ist als der der anderen Instrumente.
Die Wahl von Tonleitern ist verknüpft mit der Wahrnehmung von Amplituden- oder Frequenzschwankungen.
Schwankt die Amplitude oder die Frequenz eines Tons sehr langsam (im Bereich weniger Hertz), so werden diese Schwankungen als Änderung der Lautstärke oder der Tonhöhe des Tons wahrgenommen.
Schnellere Schwankungen (oberhalb von 10 Hertz), werden als rauer, „harter“, weniger angenehmer Ton empfunden.
Liegt die Schwankungsfrequenz wesentlich oberhalb der Wahrnehmbarkeitsschwelle für Töne (wesentlich über 20 Hertz), so können diese Schwankungen zum Wahrnehmen von Differenztönen führen. Diese Differenztöne verleihen dem Klang oft einen weniger angenehmen Charakter.Die verwendeten Töne einer Tonleiter sollen beim Zusammenklingen angenehm klingen. Das gilt nicht nur, wenn Mehrstimmigkeit als musikalisches Ausdrucksmittel verwendet wird, sondern auch bei einstimmiger Musik. Denn in halliger Umgebung erklingen aufeinander folgende Töne für kurze Zeit gleichzeitig: Der Nachhall des vorausgegangenen Tons ist noch nicht abgeklungen, wenn der nächste Ton erklingt.
Sollen Töne beim Zusammenklingen angenehm klingen, dürfen keine starken und schnellen Amplitudenschwankungen hervorgerufen werden. Das beeinflusst die Wahl einer Tonleiter erheblich:
Stehen die Töne einer Tonleiter im Verhältnis kleiner ganzer Zahlen zueinander, so wird beim Zusammenklingen ein Residualton wahrgenommen:Der Residualton liegt meistens wesentlich tiefer als die dargebotenen Einzeltöne. Die Einzeltöne werden als Obertöne des Residualtons interpretiert. Amplitude und Frequenz des Tongemischs bleiben konstant. Ein Beispiel für eine solche Tonleiter ist die reine Stimmung.
Beispiel: Bei einem rein gestimmten Dur-Akkord stehen die Tonfrequenzen im Verhältnis 4:5:6 zueinander. Es entsteht ein 2 Oktaven tieferer Residualton, die Töne des Akkords werden zum 4., 5. und 6. Oberton des Residualtons. Die Hüllkurve eines solchen Akkords ist konstant (blaue Kurve oben).
Weichen die Töne einer Tonleiter vom Verhältnis kleiner ganzer Zahlen ab, so entsteht beim Zusammenklingen ein Residualton mit Schwebungen. Die Frequenz der Schwebungen ergibt sich aus den Abweichungen vom Verhältnis kleiner ganzer Zahlen. Ein Beispiel für eine solche Tonleiter ist die heute meistens verwendete gleichstufige Stimmung oder die früher verwendeten temperierten Stimmungen Beispiel: Bei einem gleichstufig gestimmten Dur-Akkord weichen die Einzeltöne um wenige Hertz von der reinen Stimmung ab. Die Hüllkurve wird zeitveränderlich (grüne Kurve, 2. von oben).Die Änderungen der Amplitude sind aber so langsam, dass sie nicht unangenehm wirken. Aber: Ein gleichstufig gestimmter Dur-Akkord klingt nicht mehr ganz so gut, wie ein reiner Dur-Akkord.
Weichen die Töne stark vom Verhältnis kleiner ganzer Zahlen ab, so entstehen beim Zusammenklingen sehr starke und schnelle Änderungen der Amplitude (schnelle Schwebungen). Es ergibt sich ein rauer, harter, eher unangenehmer Klang.Bei größeren Abweichungen von ganzzahligen Frequenzverhältnissen ändert sich die Hüllkurve des Akkords schnell und abrupt (gelbe Kurve, 3. von oben). Das Verhalten ähnelt dem Verhalten einer Dissonanz (rote Kurve unten).
Das hat zur Konsequenz, dass Tonleitern bevorzugt werden, bei denen Töne im Verhältnis kleiner ganzer Zahlen zueinander stehen, oder die dem zumindest nahe kommen. Denn dann entstehen beim Zusammenklingen eher angenehme Klänge.
Die Wahrnehmung diskreter Tonhöhen ist wahrscheinlich universell. Schon Kinder scheinen prädisponiert zu sein, diskrete Tonhöhen zu singen. Diese kategoriale Tonhöhenwahrnehmung existiert in allen Kulturen – dadurch kann die musikalische Botschaft trotz Schwierigkeiten wie einer lauten Umgebung oder einer schlechten Intonation verstanden werden (Dowling & Harwood, 1986).
Kategorienbildung hat den Zweck, die zu verarbeitende Datenmenge zu reduzieren, und verhindert auf diese Weise eine Überlastung beim Musikhören und der musikalischen Praxis. Die konkreten Kategorien selbst sind aber erlernt und damit von Kultur zu Kultur verschieden.
Der Zweikomponententheorie von Géza Révész (1913) zufolge existiert neben der Dimension Tonhöhe als weitere Dimension das Chroma oder die Tonigkeit und in diesem Zusammenhang die Oktavidentität, die ebenfalls oft als Universalie betrachtet wird. Als Chroma wird der zyklisch wiederkehrende Toncharakter von Tönen im Oktavabstand bezeichnet. Das wird beispielsweise darin deutlich, dass verschiedene Varianten einer Melodie als äquivalent empfunden werden, wenn die gesamte Melodie oder auch nur einzelne Töne der Melodie um eine Oktave versetzt werden und die Kontur erhalten bleibt. Ohne Oktavidentität hätte jeder Ton im gesamten Hörbereich einen eigenen Toncharakter, was eine enorme Komplexität bedeuten würde. Aber durch die Oktavidentität muss unser Gehirn lediglich so viele Töne identifizieren, wie innerhalb einer Oktave vorkommen. Die Einteilung in Oktaven ordnet und strukturiert daher. Alle hoch entwickelten Musikkulturen geben Tönen im Oktavabstand denselben Namen. Oktavidentität wird auch von Affen wahrgenommen und neuere Ergebnisse der Gehirnforschung zeigen, dass auch andere Säugetiere eine Oktavkartierung haben – und zwar im auditorischen Thalamus, also zwischen Hirnstamm und Großhirn (Braun und Chaloupka, 2005).
In den meisten Kulturen kommen neben der Oktave auch Quinte und Quarte vor. Anscheinend neigt das Gehirn eher zu diesen Kategorien, denn Kombinationen von Tönen, deren Frequenzverhältnisse durch kleine ganze Zahlen gegeben sind, erzeugen im Gegensatz zu solchen mit komplizierteren Frequenzverhältnissen zusätzliche periodische Muster in Nervensignalen (z. B. hat die Oktave ein Frequenzverhältnis von 1 : 2, die Quinte von 2 : 3, die Quarte von 3 : 4, dagegen der Tritonus von 32 : 45). Das legen auch Experimente nahe, in denen Kinder und Erwachsene Tonfolgen besser erinnern konnten, deren Töne in kleinzahligen Frequenzverhältnissen standen, also beispielsweise besser Tonfolgen mit Quinte und Quarte als mit dem Tritonus (Trehub, 2000).
Umgekehrt steht die Tonhöhe in logarithmischer Beziehung zur Frequenz. Die dadurch entstehende psychophysische Skala ist universal (Justus und Bharucha, 2002).
Tonleitern haben in allen Kulturen eine relativ geringe Anzahl von Stufen, sie bestehen fast überall aus fünf bis sieben Tönen pro Oktave. Das passt gut dazu, dass die Kurzzeitgedächtnisgrenze für Kategorien bei etwa sieben liegt (Miller, 1956).
Die Anzahl der Stufen, in die die Oktave unterteilt wird, ist außerdem davon abhängig, wie differenziert Töne kategorisiert werden können.
Es gibt auch kaum äquidistante Skalen, d. h., bei Tonleitern sind die Intervalle zwischen benachbarten Tonstufen fast nie gleich groß, z. B. gibt es in der diatonischen Tonleiter Ganztöne und Halbtöne. Auf diese Weise können tonale Bezüge hergestellt werden, die Töne stehen in unterschiedlichen Beziehungen zum Grundton und der Hörer kann sich zu jedem Zeitpunkt vorstellen, wo sich die Musik in Bezug auf das tonale Zentrum der Musik befindet. Dadurch kann eine Wahrnehmung von Spannung und Auflösung entstehen, was die musikalischen Ausdrucks- und Erlebnismöglichkeiten steigert (Sloboda, 1985).
Durch diese unterschiedlichen Beziehungen zum Grundton bilden sich Tonhierarchien, die sich auch in fast jeder Kultur finden, d. h., die Töne der Tonleiter haben verschiedene Funktionen, sie treten unterschiedlich häufig und an verschiedenen Positionen in einer Melodie auf. Die spezifischen Tonhierarchien variieren aber zwischen den Kulturen (Justus & Bharucha, 2002). Es scheint eine universale Verarbeitungsprädisposition für Skalen mit ungleichen Tonabständen zu geben – solche Skalen sind leichter zu enkodieren und zu behalten als Skalen mit gleichen Abständen. Das zeigt sich schon bei Kleinkindern:
Trehub (2000) präsentierte Kindern drei Skalen – die Durtonleiter, eine neue Skala mit ungleichen Abständen und eine äquidistante Skala – und untersuchte, ob sie erkennen können, wenn ein Ton der Tonleiter um drei oder vier Halbtöne verschoben wurde. Für die Kinder waren vermutlich alle drei Skalen unbekannt, sie zeigten aber eine signifikant bessere Leistung bei den beiden Skalen mit ungleichen Abständen als bei der gleichschrittigen Skala.
Eine weitere Universalie in der Tonhöhen- und Melodiewahrnehmung hängt mit der melodischen Kontur zusammen. Der Hörer neigt dazu, eher globale, die Beziehung zwischen Tönen betreffende Informationen zu verarbeiten als präzise, absolute Reize wie spezifische Tonhöhen oder Intervalle (Trehub, 2000): Nach dem Hören einer unbekannten Melodie wird gewöhnlich kaum mehr als ihre Kontur im Gedächtnis behalten, also Richtungsänderungen der Tonhöhe. Des Weiteren werden unterschiedliche Tonfolgen mit gleicher Kontur als verwandt empfunden. Schon im Kleinkindalter hat die melodische Kontur eine große Bedeutung bei der Repräsentation von Melodien, was auf eine Universalie hindeutet. Experimente von Trehub (2000) zeigen, dass Kleinkinder eine Melodie, die transponiert wurde (Intervalle bleiben gleich) als identisch mit der Originalmelodie behandeln. Selbst wenn sich die Intervalle ändern, aber die Kontur erhalten bleibt, wird die Melodie als bekannt und nicht als neu behandelt. Wird aber auch nur ein Ton so verschoben, dass sich die Kontur ändert, kommt Kindern und Erwachsenen die Melodie unbekannt vor.
Ebenfalls universal ist der Einsatz auditiver Gruppierungsstrategien. Die Organisation von Tönen zu Wahrnehmungseinheiten steigert die Ökonomie und Leistungsfähigkeit bei der Verarbeitung von Musik, die durch die Kurzzeitgedächtniskapazität begrenzt ist. Gruppiert und strukturiert wird nach bestimmten Gestaltprinzipien, aber es ist fraglich, ob auch sie universal sind. Da die musikalische Wahrnehmung auch von gelernten Kategorien und Schemata geprägt ist, sind immer auch andere Hörweisen möglich (Motte-Haber, 1996).
Die Gruppierung von Ereignissen zu Wahrnehmungseinheiten, um Information zu reduzieren, gehört auch zu den Universalien der Rhythmuswahrnehmung. Das zeigt sich beispielsweise darin, dass wir eine Folge von Schlägen meistens zu Gruppen von zwei oder drei Schlägen von unterschiedlichem Gewicht zusammenfassen (Fricke, 1997).
In diesem Zusammenhang wird außerdem versucht, einen regelmäßigen Puls zu finden, um den herum die anderen Ereignisse organisiert werden können – es wird für eine ökonomische Verarbeitung immer aktiv nach Regelmäßigkeiten gesucht. Bestätigung findet das unter anderem in Experimenten von Drake und Bertrand (2001), bei denen die Synchronisierung bei über 90 % lag, wenn Personen zur Musik den Takt klopfen sollten, und die zeigen, dass bereits Säuglinge ihre Saugrate an die Rate einer auditiven Sequenz anpassen können.
Rhythmus ist immer auf verschiedenen Ebenen organisiert: Über den angesprochenen regelmäßigen Puls sind rhythmische Muster gelegt – der Puls wird unterteilt durch asymmetrisch angeordnete Klänge.
Die Details der rhythmischen Organisation unterscheiden sich von Kultur zu Kultur. Einer der einfachsten Rhythmen ist der Daktylus (ein langes Intervall, gefolgt von zwei kurzen); in anderen Kulturen wie im südlichen Afrika oder in Indien sind komplexere Rhythmen zu finden – hier kann die Anzahl der Schläge innerhalb des Pulses groß und ungerade sein, z. B. sind in Indien 7 bis 17 Schläge üblich.
Durch die Asymmetrie der rhythmischen Muster wird ein Ortsempfinden innerhalb des Beats hervorgerufen. Es entstehen Betonungen, die wesentlich für die Musik fast aller Kulturen sind. Diese Bezugspunkte bilden die Grundlage für ein Empfinden von Bewegung und Ruhe und geben außerdem Hinweise für die Koordination der verschiedenen Teile in polyphoner Musik (Sloboda, 1985).
Ellen Dissanayake: Kunst als menschliche Universalie. Eine adaptionistische Betrachtung. In: Peter M. Hejl (Hrsg.): Universalien und Konstruktivismus. Suhrkamp, Frankfurt/M. 2001, ISBN 3-518-29104-1, S. 206–234.
C. Drake, D. Bertrand: The quest for universals in temporal processing in music. In: Robert J. Zatorre u. a. (Hrsg.): The biological foundations of music. Academy of Science, New York 2001, (Annals of the New York Academy of Sciences; vol. 930) ISBN 1-573-31307-6, S. 17–27.
W. Jay Dowling, Dane L. Harwood: Music cognition Academic Pr., Orlando Fl. 1986, ISBN 0-122-21430-7.
J. P. Fricke: Rhythmus als Ordnungsfaktor. Informationspsychologische Bedingungen der Zeitgestaltung. In: Axel Beer u. a. (Hrsg.): Festschrift Christoph-Hellmut Mahling zum 65. Geburtstag. Schneider, Tutzing 1997, ISBN 3-795-20900-5, S. 397–412.
Robert Jourdain: Das wohltemperierte Gehirn. Wie Musik im Kopf entsteht und wirkt. Spektrum Akademischer Verl., Heidelberg 2001, ISBN 3-827-41122-X.
T. C. Justus, J. J. Bharucha: Music perception and cognition. In: Harold Pashler (Hrsg.): Stevens' handbook of experimental psychology. Wiley, New York 2002.
G. A. Miller: The magical number seven, plus or minus two. Some limits on our capacity for processing information. In: Psychological Review, 63 (1956), S. 81–97,
John A. Sloboda: The musical mind. The cognitive psychology of music. Univ. Pr., Oxford 2003, ISBN 0-198-52128-6.
S. Trehub: Human processing predispositions and musical universals. In: Nils L. Wallin u. a. (Hrsg.): The origins of music. Consists of papers given at a workshop on the "The origins of music" held in Fiesole, Italy, May 1997. MIT Pr., Cambridge, Ma. 2001, ISBN 0-262-23206-5.
Daniel Bendor, Xiaoqin Wang: The neuronal representation of pitch in primate auditory cortex. In: Nature. Bd. 436, Nr. 7054, 2005, S. 1161–1165, doi:10.1038/nature03867.
Martin Braun, Vladimir Chaloupka: Carbamazepine induced pitch shift and octave space representation. In: Hearing Research. Bd. 210, Nr. 1/2, 2005, S. 85–92, doi:10.1016/j.heares.2005.05.015.
Ulrich W. Biebel, Gerald Langner: Evidence for „pitch neurons“ in the auditory midbrain of chinchillas. In: Josef Syka (Hrsg.): Acoustical Signal Processing in the Central Auditory System. (Proceedings of an International Symposium on Acoustical Signal Processing in the Central Auditory System, held September 4–7, 1996, in Prague, Czech Republic). Plenum Press, New York NY  u. a. 1997, ISBN 0-306-45608-7, S. 263–269, doi:10.1007/978-1-4419-8712-9_24.
Ulrich W. Biebel, Gerald Langner: Evidence for interactions across frequency channels in the inferior colliculus of awake chinchilla. In: Hearing Research. Bd. 169, Nr. 1/2, 2002, S. 151–168, doi:10.1016/S0378-5955(02)00459-8.
Adrian Rees, Ali Sarbaz: The influence of intrinsic oscillations on the encoding of amplitude modulation by neurons in the inferior colliculus. In: Josef Syka (Hrsg.): Acoustical Signal Processing in the Central Auditory System. (Proceedings of an International Symposium on Acoustical Signal Processing in the Central Auditory System, held September 4–7, 1996, in Prague, Czech Republic). Plenum Press, New York NY  u. a. 1997, ISBN 0-306-45608-7, S. 239–252, doi:10.1007/978-1-4419-8712-9_22.
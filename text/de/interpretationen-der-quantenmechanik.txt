Interpretationen der Quantenmechanik beschreiben die physikalische und metaphysische Bedeutung der Postulate und Begriffe, aus welchen die Quantenmechanik aufgebaut ist. Besonderes Gewicht hat dabei die Interpretation derjenigen Konzepte, wie z. B. des Welle-Teilchen-Dualismus, die nicht nur einen Bruch mit etablierten Vorstellungen der klassischen Physik bedeuten, sondern auch der Anschauung oftmals zuwiderzulaufen scheinen.
Neben der ersten – und bis heute dominierenden – Kopenhagener Interpretation wurden seit Entwicklung der Quantenmechanik in den 1920er Jahren eine Vielzahl alternativer Interpretationen entwickelt, die sich unter anderem in ihren Aussagen über den Determinismus, die Kausalität, die Frage der Vollständigkeit der Theorie, die Rolle von Beobachtern und einer Reihe weiterer metaphysischer Aspekte unterscheiden.
Dieser Artikel gibt einen Überblick über die wichtigsten Interpretationen der nichtrelativistischen Quantenmechanik. Eine Beschreibung der konzeptionellen Grundlagen der Theorie auf Basis gängiger Lehrbuch-Darstellungen findet sich im Hauptartikel Quantenmechanik.
Hinsichtlich ihres empirischen Erfolges gilt die Quantenmechanik als eine der am besten gesicherten physikalischen Theorien überhaupt. Seit ihrer Formulierung in den 1920er Jahren konnte die Quantenmechanik bis heute experimentell nicht falsifiziert werden. Die Frage, wie die Quantenmechanik zu interpretieren ist, wird jedoch kontrovers diskutiert: Beschreibt die Theorie nur physikalische Phänomene oder erlaubt sie auch Rückschlüsse auf Elemente einer hinter den Phänomenen verborgenen Realität? Fragen zur Ontologie der Quantenmechanik lassen sich weder mit experimentellen noch mit theoretischen Methoden der Physik beantworten, weshalb sie von manchen Physikern als unwissenschaftlich angesehen werden. Allerdings zeigt sich, dass sich viele fundamentale Begriffe der Theorie, wie beispielsweise „Messung“, „physikalische Eigenschaft“ oder „Wahrscheinlichkeit“, ohne interpretativen Rahmen nicht eindeutig definieren lassen. Andere Physiker und Philosophen sehen daher die Formulierung einer konsistenten Interpretation, das heißt einer semantischen Deutung des mathematischen Formalismus, als sinnvollen, wenn nicht notwendigen Bestandteil der Theorie an.Neben der ersten und lange Zeit dominierenden Kopenhagener Interpretation entstanden im Laufe der Zeit zahlreiche alternative Interpretationen der Quantenmechanik, die im nächsten Kapitel beschrieben werden. Im Folgenden werden zunächst einige der physikalischen und philosophischen Prinzipien und Konzepte erläutert, in welchen sich die Interpretationen der Quantenmechanik voneinander unterscheiden.
Die Gesetze der klassischen Physik gelten gemeinhin als deterministisch: Kennt man den aktuellen Zustand eines abgeschlossenen Systems vollständig, kann man theoretisch sein Verhalten, also alle zukünftig möglichen Beobachtungen an diesem System für jeden beliebigen Zeitpunkt, exakt vorhersagen. Jegliches anscheinend zufällige Verhalten und jegliche Wahrscheinlichkeiten resultieren im Rahmen der klassischen Physik ausschließlich aus Unkenntnis, beziehungsweise in konkreten Experimenten aus der Unfähigkeit des Experimentators, den Zustand exakt zu präparieren, oder Unzulänglichkeiten des Messgerätes. Dieser prinzipielle Determinismus besteht auch zum Beispiel für die statistische Mechanik und Thermodynamik.
Viele Interpretationen der Quantenmechanik, darunter insbesondere die Kopenhagener Interpretation, gehen hingegen davon aus, dass die Annahme einer deterministischen Dynamik physikalischer Systeme nicht aufrechterhalten werden kann: Die Tatsache, dass es nicht möglich ist, beispielsweise den Zeitpunkt des Zerfalls eines radioaktiven Atoms vorherzusagen, ist demnach nicht darin begründet, dass ein Beobachter nicht genügend Informationen über etwaige innere verborgene Eigenschaften dieses Atoms besitzt. Vielmehr gibt es keinen Grund für den konkreten Zeitpunkt des Zerfalls; der Zeitpunkt ist „objektiv zufällig“.Eine entgegengesetzte Ansicht vertreten Befürworter von Verborgene-Variablen-Interpretationen, wie der bohmschen Mechanik. Die Quantenmechanik biete demnach keine vollständige Beschreibung der Natur, sie lasse bestimmte Einflussfaktoren außer Betracht. Wüssten wir um diese, ließe sich auch ein einzelnes künftiges Messergebnis exakt und deterministisch berechnen.
Diesem Konzept liegt die idealisierte Annahme zugrunde, dass bei Beobachtungen beziehungsweise Messungen zwischen einem beobachteten „Objektsystem“ und einem „Beobachter“ unterschieden werden kann, wobei zur Beschreibung der Eigenschaften des Objektsystems der Beobachter nicht mit in Betracht gezogen werden muss. Dieses Ideal lässt sich zwar aufgrund der zur Durchführung der Messung zwingend notwendigen Wechselwirkung zwischen Objektsystem und Messvorrichtung weder in der klassischen Physik noch in der Quantenmechanik vollständig erreichen, jedoch kann man in der klassischen Physik den Einfluss der Messapparatur auf das Objektsystem prinzipiell als beliebig minimierbar annehmen. In der klassischen Physik ist die Messung demnach kein grundsätzliches, sondern nur ein praktisches Problem.
In der Quantenmechanik kann die Annahme eines vernachlässigbaren Einflusses der Messvorrichtung hingegen nicht aufrechterhalten werden. Generell ist jede Wechselwirkung des Objektsystems mit der Messvorrichtung mit Dekohärenzprozessen verbunden, deren Auswirkungen nicht als „klein“ betrachtet werden können. In vielen Fällen (beispielsweise beim Nachweis eines Photons durch einen Detektor) wird das untersuchte Objekt bei der Messung sogar vernichtet. Die gegenseitige Beeinflussung zwischen Objektsystem und Umgebung beziehungsweise Messvorrichtung wird daher in allen Interpretationen der Quantenmechanik berücksichtigt, wobei sich die einzelnen Interpretationen in ihrer Beschreibung des Ursprungs und der Auswirkungen dieser Beeinflussung wesentlich unterscheiden.
Die von der Quantenmechanik postulierte Gesetzmäßigkeit der Zeitentwicklung des Systemzustands und das Auftreten eindeutiger Messergebnisse scheinen in direktem Widerspruch zu stehen: Einerseits erfolgt die Zeitentwicklung des Systemzustands strikt deterministisch, andererseits sind die Messergebnisse nur statistisch vorhersagbar. Einerseits sollen den Systemzuständen im Allgemeinen überlagerte Linearkombinationen von Eigenzuständen entsprechen, andererseits wird kein verwaschenes Bild mehrerer Werte gemessen, sondern stets eindeutige Werte.
Die in den meisten Lehrbüchern zugrunde gelegte orthodoxe Interpretation erklärt die Vorgänge bei der Durchführung einer quantenmechanischen Messung mit einem so genannten Kollaps der Wellenfunktion, also einem instantanen Übergang des Systemzustands in einen Eigenzustand der gemessenen Observablen, wobei dieser Übergang im Gegensatz zu sonstigen physikalischen Prozessen nicht durch die Schrödingergleichung beschrieben wird. Hierbei wird in der orthodoxen Interpretation offen gelassen, welcher Vorgang in der Messkette zu dem Kollaps führt, der Messprozess wird im Rahmen dieser Interpretation nicht genauer spezifiziert. Viele Physiker und Interpreten halten es dagegen für notwendig, in physikalischen Begriffen anzugeben, was genau eine „Messung“ ausmacht.
Die Erklärung dieses scheinbaren Widerspruchs zwischen deterministischer Systementwicklung und indeterministischen Messergebnissen ist eine der hauptsächlichen Herausforderungen bei der Interpretation der Quantenmechanik.
Ein grundsätzlicher Aspekt bei der Interpretation der Quantenmechanik ist die wissenschaftstheoretische Fragestellung, welche Art von Kenntnis über die Welt diese Theorie vermitteln kann. Die Standpunkte der meisten Interpretationen der Quantenmechanik zu dieser Frage können grob in zwei Gruppen aufgeteilt werden, die instrumentalistische Position und die realistische Position.Gemäß der instrumentalistischen Position stellen die Quantenmechanik beziehungsweise die auf Basis der Quantenmechanik ausgearbeiteten Modelle keine Abbildungen der „Realität“ dar. Vielmehr handele es sich bei dieser Theorie lediglich um einen nützlichen mathematischen Formalismus, der sich als Werkzeug zur Berechnung von Messergebnissen bewährt hat. Diese pragmatische Sicht dominierte bis in die 1960er Jahre die Diskussion um die Interpretation der Quantenmechanik und prägt bis heute viele gängige Lehrbuchdarstellungen.Neben der pragmatischen Kopenhagener Interpretation existiert heute eine Vielzahl alternativer Interpretationen, die bis auf wenige Ausnahmen das Ziel einer realistischen Deutung der Quantenmechanik verfolgen. In der Wissenschaftstheorie wird eine Interpretation als wissenschaftlich-realistisch bezeichnet, wenn sie davon ausgeht, dass die Objekte und Strukturen der Theorie treue Abbildungen der Realität darstellen und dass sowohl ihre Aussagen über beobachtbare Phänomene als auch ihre Aussagen über nicht beobachtbare Entitäten als (näherungsweise) wahr angenommen werden können.
In vielen Arbeiten zur Quantenphysik wird Realismus gleichgesetzt mit dem Prinzip der Wert-Definiertheit. Dieses Prinzip basiert auf der Annahme, dass einem physikalischen Objekt physikalische Eigenschaften zugeordnet werden können, die es eindeutig entweder hat oder nicht hat. Beispielsweise spricht man bei der Beschreibung der Schwingung eines Pendels davon, dass das Pendel (zu einem bestimmten Zeitpunkt, und innerhalb einer gegebenen Genauigkeit) eine Auslenkung x hat.
In der orthodoxen Interpretation der Quantenmechanik wird die Annahme der Wert-Definiertheit aufgegeben. Ein Quantenobjekt hat demnach im Allgemeinen keine Eigenschaften, vielmehr entstehen Eigenschaften erst im Moment und im speziellen Kontext der Durchführung einer Messung. Die Schlussfolgerung der orthodoxen Interpretation, dass die Wert-Definiertheit aufgegeben werden muss, ist allerdings weder aus logischer noch aus empirischer Sicht zwingend. So geht beispielsweise die (empirisch von der orthodoxen Interpretation nicht unterscheidbare) De-Broglie-Bohm-Theorie davon aus, dass Quantenobjekte Teilchen sind, die sich entlang wohldefinierter Bahnkurven bewegen.
Gemäß dem Prinzip der lokalen Wirkung hat die Änderung einer Eigenschaft eines Subsystems A keinen direkten Einfluss auf ein räumlich davon getrenntes Subsystem B. Einstein betrachtete dieses Prinzip als notwendige Voraussetzung für die Existenz empirisch überprüfbarer Naturgesetze. In der speziellen Relativitätstheorie gilt das Lokalitätsprinzip in einem absoluten Sinn, wenn der Abstand zwischen den zwei Subsystemen raumartig ist.
In der Quantenmechanik bewirkt die Verschränkung statistische Abhängigkeiten (so genannte Korrelationen) zwischen den Eigenschaften verschränkter, räumlich voneinander getrennter Objekte. Diese legen die Existenz gegenseitiger nicht-lokaler Beeinflussungen zwischen diesen Objekten nahe. Allerdings kann gezeigt werden, dass auch im Rahmen der Quantenmechanik keine überlichtschnelle Übertragung von Information möglich ist (siehe No-signalling-Theorem).
Das mit der quantenmechanischen Verschränkung verbundene Phänomen, dass die Durchführung von Messungen an einem Ort die Messergebnisse an einem (im Prinzip beliebig weit entfernten) anderen Ort zu beeinflussen scheint, war einer der Gründe, weshalb Einstein die Quantenmechanik ablehnte. In dem berühmten, gemeinsam mit Boris Podolsky und Nathan Rosen entwickelten EPR-Gedankenexperiment versuchte er, unter der Prämisse der Lokalität, nachzuweisen, dass die Quantenmechanik keine vollständige Theorie sein kann. Dieses Gedankenexperiment erwies sich in seiner ursprünglichen Formulierung als nicht praktisch durchführbar, jedoch gelang es John Stewart Bell im Jahr 1964, die zentrale EPR-Prämisse des lokalen Realismus, das heißt der Existenz lokaler physikalischer Eigenschaften, in der experimentell überprüfbaren Form der Bellschen Ungleichung zu formulieren. Alle bislang vorliegenden experimentellen Untersuchungen haben die Verletzung der Bellschen Ungleichung und damit die Voraussagen der Quantenmechanik bestätigt.Allerdings sind sowohl die Bewertung der Aussagekraft der Experimente als auch die Interpretation der genauen Natur der EPR/B-Korrelationen Gegenstand einer bis heute andauernden Kontroverse. Viele Physiker leiten aus den experimentellen Ergebnissen zur Bellschen Ungleichung ab, dass das Lokalitätsprinzip nicht in der von Einstein vertretenen Form gültig sei. Andere Physiker interpretieren hingegen die Quantenmechanik und die Experimente zur Bellschen Ungleichung und zur Leggettschen Ungleichung so, dass die Annahme des Realismus aufgegeben werden müsse, das Lokalitätsprinzip hingegen aufrechterhalten werden könne.
Bei der Wechselwirkung eines Quantensystems mit seiner Umgebung (beispielsweise mit Gasteilchen der Atmosphäre, mit einfallendem Licht oder mit einer Messapparatur) kommt es unweigerlich zu Dekohärenz-Effekten. Das Phänomen der Dekohärenz lässt sich unmittelbar aus dem Formalismus der Quantenmechanik ableiten. Es stellt daher keine Interpretation der Quantenmechanik dar. Dennoch spielt Dekohärenz bei den meisten modernen Interpretationen eine zentrale Rolle, da sie einen unverzichtbaren Bestandteil bei der Erklärung des „klassischen“ Verhaltens makroskopischer Objekte darstellt und damit für jeden Versuch relevant ist, die Diskrepanz zwischen den ontologischen Aussagen der Interpretationen der Quantenmechanik und der Alltagserfahrung zu erklären.
Dekohärenz führt zu einer irreversiblen Auslöschung der Interferenzterme in der Wellenfunktion: Bei großen Systemen (ein Fulleren ist in dieser Hinsicht bereits als „groß“ anzusehen) ist dieser Mechanismus äußerst effizient. Die Dekohärenz macht somit verständlich, warum bei makroskopischen Systemen keine Superpositionszustände beobachtet werden:
Dekohärenz verursacht eine selektive Dämpfung aller Zustände, die nicht bestimmten Stabilitätskriterien genügen, die durch die Details der Wechselwirkung zwischen dem System und seiner Umgebung definiert sind. Diese so genannte Einselection (Abkürzung für „environmentally-induced-superselection“, d. h. „umgebungsinduzierte Superselektion“) führt zur Ausprägung bevorzugter „robuster“ Zustände, d. h. von Zuständen, die nicht durch die Dekohärenz zerstört werden.
Die tatsächlich beobachtbaren Observablen sind durch diese robusten Zustände bestimmt. Modellrechnungen zeigen, dass das Coulomb-Potential, das (unter Normalbedingungen) wichtigste für den Aufbau von Materie relevante Wechselwirkungspotential, zu einer Superselektion räumlich lokalisierter Zustände führt. Das Auftreten lokalisierter makroskopischer Zustände von Alltagsgegenständen kann so auch im Rahmen der Quantenmechanik erklärt werden.
Messvorrichtungen sind immer makroskopische Objekte und unterliegen damit der Dekohärenz. Das Auftreten eindeutiger Zeigerzustände bei der Durchführung von Messungen lässt sich damit zwanglos erklären. Allerdings löst auch die Dekohärenz das Messproblem nicht vollständig, da sie nicht beschreibt, wie es zum Auftreten eines konkreten Ereignisses (z. B. des Zerfalls eines Atoms) kommt. Hierfür müssen auch im Rahmen des Dekohärenz-Programms zusätzliche Annahmen, wie z. B. das Postulat eines Kollapses oder die Annahmen der viele-Welten-Interpretation, zugrunde gelegt werden.
Der Begriff der „Kopenhagener Interpretation“ wurde erstmals 1955 in einem Essay von Werner Heisenberg als Bezeichnung für eine vereinheitlichte Interpretation der Quantenmechanik verwendet, wobei Heisenberg weder in diesem Artikel noch in späteren Veröffentlichungen eine präzise Definition dieser Interpretation formulierte. Dieses Fehlen einer autoritativen Quelle und der Umstand, dass die Konzepte Heisenbergs, Bohrs und der anderen Gründungsväter der Kopenhagener Interpretation in einigen Aspekten untereinander unverträglich sind, führten dazu, dass heute unter dem Begriff der „Kopenhagener Interpretation“ ein breites Spektrum verschiedener Interpretationsvarianten subsumiert wird.
Ein besonderes Kennzeichen von Bohrs Interpretation ist seine Betonung der Rolle der klassischen Physik bei der Beschreibung von Naturphänomenen. Demnach wird zur Beschreibung von Beobachtungsergebnissen – wie wenig der untersuchte Vorgang auch mit der klassischen Mechanik zu tun haben mag – notwendig die klassische Terminologie benutzt. So spricht man beispielsweise von Zählraten beim Nachweis von Teilchen an einem Detektor. Messvorrichtungen und Messergebnisse sind prinzipiell nur in der Sprache der klassischen Physik beschreibbar. Für eine vollständige Beschreibung eines physikalischen Phänomens muss daher die quantenmechanische Beschreibung mikroskopischer Systeme um die Beschreibung der verwendeten Messapparatur ergänzt werden. Hierbei spielt die Messapparatur nicht nur die passive Rolle eines losgelösten Beobachters (siehe oben), vielmehr ist jeder Messvorgang gemäß dem Quantenpostulat unvermeidlich mit einer Wechselwirkung zwischen Quantenobjekt und Messapparatur verbunden. Je nach verwendeter Messvorrichtung weist das Gesamtsystem (Quantenobjekt + Messvorrichtung) daher unterschiedliche komplementäre Eigenschaften auf (siehe Komplementaritätsprinzip). Da z. B. die Messung der Position und die Messung des Impulses eines Teilchens unterschiedliche Messvorrichtungen erfordern, stellen Position und Impuls zwei unterschiedliche Phänomene dar, die grundsätzlich nicht in einer einheitlichen Beschreibung zusammengefasst werden können.
Bohr verneinte die Möglichkeit einer realistischen Interpretation der Quantenmechanik. Er betrachtete das Komplementaritätsprinzip als eine prinzipielle epistemologische Grenze und lehnte daher ontologische Aussagen über die „Quantenwelt“ ab. Auch zum Formalismus der Quantenmechanik hatte Bohr eine rein instrumentalistische Einstellung, die Wellenfunktion war für ihn nicht mehr als ein mathematisches Hilfsmittel zur Berechnung der Erwartungswerte von Messgrößen unter wohldefinierten experimentellen Bedingungen.
Im Gegensatz zu Bohr vertrat Heisenberg eine Interpretation der Quantenmechanik mit realistischen und subjektivistischen Elementen. Gemäß Heisenberg repräsentiert die Wellenfunktion zum einen eine objektive Tendenz, die von ihm so bezeichnete „Potentia“, dass ein bestimmtes physikalisches Ereignis eintritt. Zum anderen enthält sie „Aussagen über unsere Kenntnis des Systems, die natürlich subjektiv sein müssen“. Hierbei kommt dem Messvorgang eine entscheidende Rolle zu:
Die Beobachtung selbst ändert die Wahrscheinlichkeitsfunktion unstetig. Sie wählt von allen möglichen Vorgängen den aus, der tatsächlich stattgefunden hat. Da sich durch die Beobachtung unsere Kenntnis des Systems unstetig geändert hat, hat sich auch ihre mathematische Darstellung unstetig geändert, und wir sprechen daher von einem „Quantensprung“. […] Wenn wir beschreiben wollen, was in einem Atomvorgang geschieht, müssen wir davon ausgehen, dass das Wort „geschieht“ sich nur auf die Beobachtung beziehen kann, nicht auf die Situation zwischen zwei Beobachtungen. Es bezeichnet dabei den physikalischen, nicht den psychischen Akt der Beobachtung.John von Neumann („orthodoxe Interpretation“)Die von John von Neumann und P.A.M. Dirac erarbeiteten mathematischen Methoden bilden bis heute das formale Fundament der orthodoxen Interpretation. Charakteristische Merkmale der orthodoxen Interpretation sind die Annahme des so genannten „Eigenwert-Eigenzustand-Link“ und das Kollaps-Postulat.
Gemäß dem Eigenwert-Eigenzustand-Link hat eine Observable dann – und nur dann – einen definierten (d. h. prinzipiell vorhersagbaren) Wert, wenn sich das System in einem Eigenzustand der Observablen befindet. Wenn sich das System hingegen in einem Superpositionszustand verschiedener Eigenzustände befindet, kann der Messgröße in dieser Interpretation kein definierter Wert zugeordnet werden. Der Ausgang eines einzelnen Messvorgangs ist in diesem Fall zufällig, die Entwicklung des Systems ist bei Durchführung einer Messung nicht deterministisch.
Bei der Beschreibung des Messprozesses ging von Neumann im Unterschied zu Bohr davon aus, dass neben dem Objektsystem auch die Messvorrichtung quantenmechanisch dargestellt werden muss. Zur Vermeidung des Messproblems übernahm er Heisenbergs Konzept des „Kollapses der Wellenfunktion“.
Gemäß der Ensemble-Interpretation beschreibt der quantenmechanische Zustand ein Ensemble ähnlich präparierter Systeme (z. B. den Zustand eines einzelnen Atoms). Sie widerspricht der Annahme der Kopenhagener Interpretation, dass die Quantenmechanik eine vollständige Beschreibung der Eigenschaften mikroskopischer Objekte darstellt und daher auch die Eigenschaften eines einzelnen Systems vollständig beschreibt. Frühe Befürworter der Ensemble-Interpretation waren unter anderen A. Einstein und K. R. Popper. Heute vertritt diese Interpretation insbesondere der kanadische Physiker Leslie Ballentine.Bis in die 1970er Jahre gingen die meisten Vertreter der Ensemble-Interpretation davon aus, dass das Auftreten von Wahrscheinlichkeiten in der Quantenmechanik eine Folge ihrer Unvollständigkeit ist, dass mikroskopische Objekte in Wirklichkeit exakt determinierte Werte („PIVs“) für alle ihre dynamischen Größen (insbesondere: Position und Impuls) haben und die Quantenmechanik nur nicht in der Lage ist, diesen Sachverhalt vollständig zu beschreiben. Damit sind diese frühen Ensemble-Interpretationen eng verwandt zu den Verborgene-Variablen-Theorien.
Durch die Bellsche Ungleichung ist der Spielraum für PIV-Ensemble-Interpretationen stark eingeschränkt. Die „minimale Ensemble-Interpretation“ verzichtet daher auf die Annahme von PIVs. Zur Determiniertheit physikalischer Größen macht sie keine Aussage.
Die De-Broglie-Bohm-Theorie, häufig auch als „bohmsche Mechanik“ bezeichnet, geht davon aus, dass Quantenobjekte, wie z. B. Elektronen, Teilchen sind, die sich entlang wohldefinierter Bahnkurven bewegen. Die Bahnkurve eines solchen Teilchens lässt sich durch eine Bewegungsgleichung („Führungsgleichung“) berechnen. Eine andere (mathematisch äquivalente) Formulierung dieser Theorie führt ein so genanntes „Quantenpotential“ ein, welches aus der schrödingerschen Wellenfunktion abgeleitet wird und unter dessen Wirkung die Teilchenbewegung erfolgt.
Nach dieser Theorie ist der physikalische Zustand eines Teilchens also nicht nur durch die Wellenfunktion, sondern erst durch die Kombination aus Wellenfunktion und Teilchenposition vollständig definiert. Da diese Definition über die Zustandsdefinition der orthodoxen Interpretation hinausgeht, wird die Teilchenposition in der Terminologie der Quantenphysik als eine verborgene Variable bezeichnet, die De-Broglie-Bohm-Theorie zählt damit zur Klasse der Verborgene-Variablen-Theorien.
Die Dynamik der De-Broglie-Bohm-Theorie ist deterministisch. Wäre die Ausgangsposition eines Teilchens und die Wellenfunktion zu einem Zeitpunkt t₀ bekannt, ließe sich seine Position zu einem beliebigen späteren Zeitpunkt berechnen. Der beobachtete indeterministische Charakter von Quantenphänomenen wird in dieser Theorie auf die faktische Unmöglichkeit zurückgeführt, die Anfangswerte zu bestimmen, da im Rahmen dieser Interpretation der Versuch einer Ermittlung dieser Anfangswerte auf den Versuch einer Ermittlung der initialen Gesamtwellenfunktion des Universums hinausläuft.Eine Eigenschaft der De-Broglie-Bohm-Theorie, in der sie sich wesentlich zur klassischen Physik unterscheidet, ist ihr explizit nichtlokaler Charakter: Bei einem Mehrteilchensystem führt jede Änderung an einem Teilchen zu einer instantanen Änderung der Gesamtwellenfunktion; diese Änderung beeinflusst unmittelbar das Quantenpotential und damit die Bahnkurven aller Teilchen des Mehrteilchensystems, unabhängig vom Abstand zwischen den Teilchen.
Die Viele-Welten-Interpretation entstand ausgehend von einer Veröffentlichung von Hugh Everett aus dem Jahr 1957. In dieser Arbeit hat Everett den Ansatz untersucht, wonach der physikalische Zustand des gesamten Universums mit allen darin enthaltenen Objekten durch eine einzige universale Wellenfunktion beschrieben werden soll, die sich gemäß einer durch eine Schrödingergleichung gegebenen Dynamik entwickeln soll. Diese Arbeit wirft somit die Frage auf, inwieweit der Kollaps der Wellenfunktion durch die Grundprinzipien der Quantenmechanik selbst beschrieben werden muss.
Während nach der  bornschen Wahrscheinlichkeitsinterpretation die Wellenfunktion die Wahrscheinlichkeiten für das Auftreten verschiedener möglicher Messergebnisse beschreibt, von welchen dann bei Durchführung einer Messung nur eines realisiert wird, entwickelten in der Folge die Autoren der Viele-Welten-Interpretation die Vorstellung, dass alle physikalisch möglichen Ereignisse auch tatsächlich realisiert werden. Um keine Widersprüche zur Realität zu erhalten, wird dabei jedoch davon ausgegangen, dass „Beobachter“ keine vollständige Sicht auf diese parallel stattfindenden Ereignisse haben können. Dabei wird auch angenommen, dass bei einer Messung oder auch allgemeiner bei jeder physikalischen Wechselwirkung an einem überlagerten Quantensystem mehrere überlagerte „Welten“ entstehen, wobei in jeder dieser Welten jeweils nur eines der verschiedenen möglichen Ergebnisse realisiert ist. 
Welten, die sich in makroskopischen Größenordnungen voneinander unterscheiden, entwickeln sich aufgrund von Dekohärenzeffekten fast unabhängig voneinander, weshalb ein Beobachter im Normalfall nichts von der Existenz der anderen Welten bemerkt. Das einzige nachweisbare Indiz der Existenz der anderen Welten sind Interferenzeffekte, die sich beobachten lassen, wenn sich die Welten nur auf mikroskopischer Ebene (z. B. in den Bahnkurven einzelner Photonen beim Durchlaufen eines Interferometers) unterscheiden.
Die Viele-Welten-Interpretation wird sehr kontrovers diskutiert. Befürworter, wie der Physiker D. Deutsch oder der Philosoph D. Wallace, betonen, dass sie die einzige realistische Interpretation sei, die das Messproblem ohne Modifikation des Formalismus der Quantenmechanik löse. Auch in der Quantenkosmologie wurde die Viele-Welten-Interpretation als konzeptioneller Rahmen zur Beschreibung der Entwicklung des Universums verwendet.Kritiker werfen ihr eine extravagante Ontologie vor. Es gibt bislang auch keinen Konsens darüber, wie in einem Multiversum, in dem alle physikalisch möglichen Ereignisse tatsächlich stattfinden, unterschiedliche Wahrscheinlichkeiten für die verschiedenen Ereignisse erklärt werden können.
Die konsistente-Historien-Interpretation besteht im Kern aus einem Satz an Regeln, die festlegen, wie die zeitliche Entwicklung eines physikalischen Systems in Form so genannter „konsistenter Historien“ beschrieben werden kann. Eine Historie ist hier (ähnlich den bewegten Bildern in einem Film) als zeitlich geordnete Sequenz physikalischer Ereignisse definiert. Beispielsweise können bei dem rechts dargestellten einfachen Experiment folgende zwei Historien formuliert werden:
„Ein Photon befindet sich zur Zeit t₀ in der Region A und bewegt sich auf den Strahlteiler zu. Zur Zeit t₁, nach Passieren des Strahlteilers, sind für das Photon zwei unterschiedliche Routen möglich: Entweder bewegt es sich auf den Detektor D1 zu, oder auf den Detektor D2.“Die zwei Historien (Bewegung in Richtung D1 bzw. in Richtung D2) bilden hierbei eine so genannte „Historienfamilie“. Als konsistent gelten Historienfamilien, wenn ihre Wahrscheinlichkeit identisch zur Summe der Wahrscheinlichkeiten der einzelnen Historien der Familie ist, d. h. wenn die einzelnen Historien nicht interferieren. Inkonsistenten Historienfamilien kann keine Wahrscheinlichkeit zugeordnet werden, sie sind physikalisch nicht sinnvoll.
Die konsistenten Historienfamilien sind durch die Konsistenzbedingungen nicht eindeutig festgelegt, vielmehr lassen die Konsistenzregeln mehrere alternative inkompatible Historienfamilien zu. Beispielsweise lässt sich in dem oben beschriebenen Strahlteiler-Experiment die Bewegung eines Photons alternativ durch drei einander ausschließende konsistente Historienfamilien beschreiben, 1.) durch die oben beschriebene „Teilchen-Historienfamilie“, 2.) durch eine „Interferenz-Historienfamilie“ oder 3.) durch eine Historienfamilie mit einem makroskopischen Überlagerungszustand des Gesamtsystems. Die Interpretation trifft keine Aussage, welche der alternativen Historienfamilien die „richtige“ ist. Dies ist das Messproblem in der Terminologie der konsistente-Historien-Interpretation.
Die konsistente-Historien-Interpretation wurde seit ihrer Einführung im Jahr 1984 durch R. Griffiths mehrfach weiterentwickelt. Ab 1988 arbeitete R. Omnes eine explizit logische Formulierung der Quantenmechanik auf Basis konsistenter Historien aus. 1990 integrierten M. Gell-Mann und J. Hartle die Dekohärenz als Bedingung praktisch interferenzfreier Historienfamilien in die Konsistenzbedingungen. Konsistente Historienfamilien werden seither auch häufig als „dekohärente Historien“ bezeichnet.
Als Vorteil der Interpretation gilt ihr Verzicht auf metaphysisches „Gepäck“, wie z. B. die Annahme der Existenz vieler unbeobachtbarer Welten, oder die Annahme einer speziellen Rolle von Beobachtern, des Bewusstseins oder des Messprozesses. Da sie auf geschlossene Systeme anwendbar ist, wird sie auch in der Quantenkosmologie als konzeptioneller Rahmen zugrunde gelegt.Allerdings weist auch die konsistente-Historien-Interpretation konzeptionelle Probleme auf. Insbesondere die Tatsache, dass sie keine Lösung des Messproblems anbietet, wird als Nachteil dieser Interpretation angesehen.
Die Grundidee der dynamischer-Kollaps-Theorien ist die Lösung des Messproblems durch die Annahme, dass der Zustand von Quantensystemen zu zufälligen Zeitpunkten spontan in einen räumlich lokalisierten Zustand kollabiert. Zur Beschreibung der Kollaps-Vorgänge wird die Schrödingergleichung um nichtlineare und stochastische Terme erweitert, die so gewählt sind, dass die Lokalisierungsrate bei isolierten mikroskopischen Systemen praktisch vernachlässigbar, bei makroskopischen Systemen hingegen dominant ist. Die Theorie erklärt damit, weshalb die aus der Schrödingergleichung resultierenden Überlagerungszustände nur bei mikroskopischen Systemen auftreten, während makroskopische Systeme immer in lokalisiertem Zustand vorgefunden werden.
Die älteste vollständig ausgearbeitete dynamischer-Kollaps-Theorie ist die so genannte GRW-Theorie (nach ihren Autoren Ghirardi, Rimini und Weber), deren Grundzüge erstmals im Jahr 1984 formuliert wurden. Die ursprüngliche Fassung der GRW-Theorie wies zunächst noch einige schwerwiegende Probleme auf, unter anderem war sie nicht auf Systeme identischer Teilchen anwendbar, und es ergaben sich zunächst Schwierigkeiten beim Versuch einer relativistischen Verallgemeinerung. Im Rahmen verschiedener Weiterentwicklungen konnten diese Schwierigkeiten jedoch gelöst werden. Zu den ausgereiftesten Varianten der dynamischer Kollaps-Theorien zählen heute das CSL-Modell (englische Abkürzung für „Continuous Spontaneous Localization“), sowie R. Tumulkas rGRWf-Theorie (Abkürzung für „relativistische GRW-Theorie mit flash-Ontologie“).Die GRW-Theorie entstand zunächst als rein phänomenologischer Ansatz zur Lösung des Messproblems. Eine Reihe von Physikern, darunter T. P. Singh, R. Penrose und L. Diósi, vermuten jedoch auch aufgrund theoretischer Überlegungen zur Quantengravitation, dass die Wirkung der (Selbst-)Gravitation bei massebehafteten Quantensystemen mit nichtlinearen Effekten verbunden ist, welche zu dynamischen Kollapsprozessen führen. Im nichtrelativistischen Fall wird dies durch die Schrödinger-Newton-Gleichung beschrieben.
Da sich die Grundgleichungen der dynamischer-Kollaps-Theorien von der Schrödingergleichung unterscheiden, handelt es sich bei diesen Theorien genaugenommen nicht um Interpretationen der Quantenmechanik, sondern um alternative Theorien, deren Abweichungen zur Quantenmechanik im Prinzip experimentell überprüfbar sind. Allerdings erfordert der Nachweis dieser Abweichungen die kontrollierte Erzeugung makroskopischer Quantenzustände in einer Größenordnung, die mit den heute verfügbaren technischen Mitteln nicht realisierbar ist.
Bereits die älteste Interpretation der Quantenmechanik, die Kopenhagener Interpretation, enthält in manchen Varianten subjektivistische Elemente (siehe oben). W. Heisenberg, W. Pauli, R. Peierls und andere vertraten den Standpunkt, dass die Quantenmechanik nicht die Eigenschaften von Quantensystemen beschreibt, sondern „unsere Kenntnis ihres Verhaltens“. Allerdings wurden mögliche Zusammenhänge zwischen subjektiver Kenntnis, Information und Quantenmechanik bis in die 1980er Jahre weder in der Physik noch in der Informatik systematisch untersucht.
Mit dem Aufkommen der Quanteninformatik in den 1990er Jahren verdichteten sich die Hinweise, dass Quantenphänomene als neuartige (d. h. im Rahmen der klassischen Informatik unbekannte) Ressourcen zur Übertragung und Verarbeitung von Information verwendet werden können. Untersuchungen der theoretischen Grundlagen von Quantencomputern, der Quantenteleportation, der Quantenkryptografie und anderen neuen Ansätzen der Quanteninformatik zeigten eine Reihe enger Zusammenhänge und Abhängigkeiten zwischen den Konzepten der Informatik und der Quantenmechanik.
Einige Physiker und Philosophen zogen hieraus den Schluss, dass auch eine zufriedenstellende Interpretation der Quantenmechanik nur aus einer informationstheoretischen Perspektive möglich ist. Heute existieren verschiedene Varianten informationsbasierter Interpretationen, die sich unter anderem in ihrer Definition des Begriffs „Information“ unterscheiden: Bei einigen Interpretationsvarianten bezeichnet Information die (subjektive) Einschätzung eines Beobachters (siehe übernächster Abschnitt). Die im Folgenden beschriebenen informationstheoretischen Rekonstruktionen der Quantenmechanik basieren hingegen auf der technischen Definition von Information als der Größe, deren Informationsgehalt durch die von-Neumannsche Entropie bemessen ist.
Verschiedene Philosophen, wie z. B. J. Bub oder A. Grinbaum, sehen eine Ursache für viele Interpretationsprobleme in der Verwendung einer ungeeigneten Methodik: Bei den meisten Interpretationen wird der mathematische Formalismus vorausgesetzt und dann versucht, den formalen Begriffen der Theorie, wie z. B. dem quantenmechanischen Zustand, eine semantische Bedeutung zu geben. Diese Methode habe sich jedoch nicht bewährt. Vielmehr sei analog zu Einsteins Vorgehensweise bei der Herleitung der Relativitätstheorie eine Rekonstruktion der Quantenmechanik erforderlich, d. h. ihre Ableitung aus geeignet gewählten physikalischen Prinzipien. Erst aus der Perspektive dieser Prinzipien lasse sich eine sinnvolle Interpretation der Quantenmechanik formulieren.
Es existiert eine Reihe verschiedener Vorschläge für axiomatische Rekonstruktionen der Quantenmechanik, wobei die meisten entsprechenden Ansätze seit Anfang der 1990er auf informationstheoretischen Prinzipien basieren. Neben Rovellis „Relationaler Interpretation“ und Zeilingers „Grundprinzip der Quantenphysik“ zählt das CBH-Theorem zu den bekanntesten informationsbasierten Rekonstruktionen.
In informationstheoretischen Rekonstruktionen der Quantenmechanik hat Information den Status einer physikalischen Fundamentalgröße. Quantentheorien sind in diesen Interpretationen keine Theorien über die Eigenschaften materieller Objekte, sondern über die Darstellung und Manipulation von Information. Die hier zugrundeliegende Idee, dass Physik auf Information zurückführbar ist, gewann in den letzten Jahren mit dem Aufkommen der Quanteninformatik an Bedeutung. Der bekannteste Vertreter und Vordenker dieser Denkschule, der Physiker J. A. Wheeler, formulierte 1990 seine „it from bit“-These, der zufolge alle physikalischen Objekte, wie z. B. Elementarteilchen, Kraftfelder, selbst die Raumzeit, einen informationstheoretischen Ursprung haben.Einige Interpreten, wie z. B. G. Jaeger oder A. Duwell, halten diesen Standpunkt für eine unhaltbare Extremposition: Insbesondere sei Information nicht als physikalische Substanz (d. h. als physikalische Materie) zu betrachten, Information sei daher nicht als Grundbegriff zur Beschreibung der Eigenschaften von Materie geeignet. Andererseits bezweifelt der Philosoph C. Timpson, dass mit informationstheoretischen Interpretationen eine immaterialistische Position begründet werden kann: Letztlich liefen auch diese Interpretationen entweder auf eine instrumentalistische Position oder auf Verborgene-Variablen-Theorien hinaus.
Mit dem Quanten-Bayesianismus entstand in den letzten Jahren eine konsequent subjektivistische Interpretation der Quantenmechanik. Die Physiker C. Fuchs, Carlton M. Caves, R. Schack und andere zeigten, dass die Quantenmechanik in konsistenter Weise auf Basis des Bayesschen Wahrscheinlichkeitskonzeptes formuliert werden kann. Demnach bezieht sich die Wellenfunktion nicht auf ein Quantensystem, sondern sie repräsentiert die Einschätzung eines rationalen Agenten über das Ergebnis einer Messung an einem System. Der Kollaps der Wellenfunktion bei der Durchführung einer Messung beschreibt im Rahmen dieser Interpretation keinen realen physikalischen Prozess, sondern die Aktualisierung der Einschätzung des Agenten über den möglichen Ausgang einer weiteren Messung an dem System.
Der Quanten-Bayesianismus enthält sowohl realistische als auch anti-realistische Elemente: Physikalische Objekte, wie z. B. Elektronen, Neutrinos oder Quarks, werden als existierend angenommen. Jedoch besitzen Quantensysteme im Rahmen dieser Interpretation nur dispositionelle Eigenschaften, d. h. die Fähigkeit, im Falle von Wechselwirkungen mit anderen Quantensystemen bestimmte physikalische Ereignisse zu verursachen. Der Verlauf dieser Ereignisse ist durch kein physikalisches Gesetz bestimmt, selbst die Gültigkeit stochastischer Gesetzmäßigkeiten auf mikroskopischer Ebene wird in dieser Interpretation verneint.Als Vorteil des Quanten-Bayesianismus führen seine Anhänger an, dass viele der gängigen (scheinbaren) Paradoxien der Quantenmechanik, wie z. B. das Wigners Freund-Paradoxon, im Rahmen dieser Interpretation vermieden werden können, da die meisten dieser Paradoxien auf einer objektiven Interpretation des quantenmechanischen Zustandes basieren. Weiterhin vertreten sie in der (unabhängig von der Quantentheorie existierenden) Kontroverse um die Interpretation von Wahrscheinlichkeit den Bayesschen Standpunkt, dass nur eine subjektivistische Wahrscheinlichkeitsinterpretation ohne logische Inkonsistenzen formulierbar sei.
Andere Autoren, wie der Physiker G. Jaeger oder der Philosoph C. Timpson, kritisieren, dass der Quanten-Bayesianismus ein Defizit an Erklärungsvermögen aufweise. Die Zielsetzung von Physik sei die Beschreibung und Erklärung der Eigenschaften physikalischer Systeme, nicht die Beschreibung der Einschätzungen von Agenten.
Neben den in den letzten Abschnitten erwähnten Interpretationen entstanden im Zeitraum seit ca. 1980 eine Reihe weiterer Interpretationen mit einem etwas geringeren Bekanntheitsgrad. Hierzu zählen unter anderem die Modale Interpretation, die
Transactional Interpretation, sowie die Empiricist Interpretation (zu den drei letztgenannten Interpretationen sind keine deutschen Übersetzungen etabliert).
Nachdem Mitte 1926 die Ausarbeitung des Formalismus der Quantenmechanik weitgehend abgeschlossen war, verschärfte sich unter den Quantenphysikern jener Zeit die Frage nach einer zufriedenstellenden Interpretation der Quantenmechanik. Innerhalb kurzer Zeit, bis Ende 1927, setzten sich Bohr und Heisenberg gegen die Opposition Einsteins und Schrödingers weitgehend in der wissenschaftlichen Gemeinschaft durch. Die grundsätzlichen Fragen zur Quantenmechanik wurden als geklärt angesehen, und die meisten Physiker wandten sich den vielfältigen Anwendungen der Theorie zu. Selbst spätere Kritiker der Kopenhagener Interpretation, wie z. B. Landé, Louis Victor de Broglie oder David Bohm, traten zunächst für diese Interpretation ein.
In den 1950er Jahren wurde die Beschäftigung mit den konzeptionellen Grundlagen der Quantenmechanik von den meisten Physikern als philosophische und nicht als wissenschaftliche Aktivität betrachtet. Gegen den wissenschaftlichen Mainstream befassten sich einzelne Physiker kritisch mit den Prinzipien der Kopenhagener Interpretation. Der Physiker D. Bohm bewies mit der De-Broglie-Bohm-Theorie, dass die Formulierung empirisch adäquater verborgene-Variablen-Theorien möglich ist. Bei der Analyse der grundlegenden Prämissen dieser Theorien gelang J. Bell mit der Formulierung des Bellschen Theorems ein wissenschaftlicher Durchbruch, der wesentlich dazu beitrug, dass sich Untersuchungen der Grundlagen der Quantenphysik ab Anfang der 1970er Jahre zu einem rasch wachsenden Forschungsgebiet der Physik entwickelten.
Die Schwierigkeiten bei der Interpretation der Quantenmechanik, wie z. B. die vielfach als unzureichend empfundene Behandlung des Messproblems in der orthodoxen Interpretation, waren ein wesentliches Motiv für die Ausarbeitung bzw. Weiterentwicklung der im letzten Kapitel beschriebenen Alternativ-Interpretationen. Fortschritte auf experimenteller Seite, konzeptionelle Weiterentwicklungen der Theorie, wie z. B. die Ausarbeitung des Dekohärenz-Programms, sowie neue Entwicklungen auf dem Gebiet der Quanteninformatik trugen zusätzlich zu einem bis heute anhaltenden Interesse vieler Physiker und Philosophen an der Grundlagenforschung zur Quantenmechanik bei.
Bei der experimentellen Untersuchung verschiedener grundlegender Quantenphänomene wurden in den letzten Jahrzehnten erhebliche experimentelle Fortschritte erzielt. Alle diese Experimente zeigen, dass die Prinzipien der klassischen Physik nicht auf Quantensysteme übertragbar sind, während bislang keine Abweichungen zu den theoretischen Ergebnissen der Quantenmechanik nachgewiesen werden konnten. Allerdings sind die bislang durchgeführten Experimente nicht zur Unterscheidung zwischen den verschiedenen Interpretationen der Quantenmechanik geeignet, weshalb sich der folgende Überblick auf eine kurze Aufzählung der bekanntesten Schlüsselexperimente seit 1970 beschränkt:
Experimente zum lokalen Realismus („Bell-Test-Experimente“): - Experimente zur Bellschen Ungleichung; GHZ-Experiment; Experimente zur Leggett-Ungleichung
1970 stellte der Heidelberger Physiker Dieter Zeh fest, dass viele der (scheinbaren) Paradoxien der Quantenmechanik, wie z. B. das Wigners-Freund-Paradoxon und das Messproblem, unter anderem durch falsche Prämissen bei der Beschreibung der Messvorrichtung bzw. des Beobachters begründet sind. Insbesondere zeigte er, dass makroskopische Quantensysteme aufgrund unvermeidlicher Wechselwirkungen mit der Umgebung nicht als geschlossene Systeme betrachtet werden können, und schlug daher als Lösungsansatz vor, dass die Umgebung der Messvorrichtung (bzw. des Beobachters) in der quantenmechanischen Beschreibung des Messprozesses berücksichtigt wird. Allerdings wurden Zehs Anregungen bis Anfang der 1980er Jahre kaum beachtet.
1981–1982 erfolgte die Ausarbeitung der wesentlichen Konzepte der Dekohärenz durch Wojciech Zurek. 1991 veröffentlichte er einen Artikel in der Zeitschrift „Physics Today“ und machte die Dekohärenz damit einer breiteren Öffentlichkeit bekannt. In den Folgejahren entwickelte sich die Dekohärenz zum Gegenstand zahlreicher experimenteller und theoretischer Untersuchungen. Diese Arbeiten warfen ein neues Licht auf den quantenmechanischen Messprozess und auf den Zusammenhang zwischen Quantenmechanik und klassischer Physik, was in der Folge dazu führte, dass die Konzepte der Dekohärenz in vielen Interpretationen der Quantenmechanik als zentrale Bestandteile integriert wurden.
A. Cabello: Bibliographic guide to the foundations of quantum mechanics and quantum information. In: Quantum Physics. 2000, S. 1–462, arxiv:quant-ph/0012089v12 (Umfangreiche Bibliographie über Veröffentlichungen zu den Grundlagen der Quantenmechanik, mit über 10.000 Referenzen.).
David Albert: Quantum Mechanics and Experience. Harvard University Press, Cambridge 1992. (Gut lesbare Einführung mit einfachen Modellen.)
Giorgio Auletta: Foundations and Interpretation of Quantum Theory. World Scientific, Singapore 2000, ISBN 981-02-4039-2. (Umfassende Darstellung der Grundlagen der Quantenmechanik und ihrer Interpretationen.)
K. Baumann und R.U. Sexl (Hrsg.): Die Deutungen der Quantentheorie. 3. überarbeitete Auflage, Vieweg, Braunschweig 1987, ISBN 3-528-08540-1. (Nützliche Sammlung klassischer Texte in deutscher Übersetzung.)
John Stewart Bell: Speakable and Unspeakable in Quantum Mechanics, 2. Aufl., Cambridge University Press, Cambridge 2004, ISBN 978-0521523387 (mit einer Einführung von Alain Aspect, bündelt Bells Originalaufsätze, dt. Übersetzung: Quantenmechanik, Sechs mögliche Welten und weitere Artikel, de Gruyter, Berlin 2015, ISBN 978-3-11-044790-3).
Nancy Cartwright: Another Philosopher Looks at Quantum Mechanics, or: What Quantum Theory is Not (PDF; 201 kB). (Instrumentalistische Reaktion auf Putnam 2005: Quantenmechanik kann als „lebende und arbeitende Theorie“ uninterpretiert bleiben.)
Hong Dingguo: On the Neutral Status of QM in the Dispute of Realism vs. Anti-Realism., in: Cohen, Robert S / Hilpinen, Risto / Renzong, Qiu (Herausgeber): Realism and Anti-Realism in the Philosophy of Science. Kluwer Academic Publishers, Dordrecht 1996, S. 307–316.
Peter Forrest: Quantum metaphysics. Blackwell, Oxford 1988, ISBN 0-631-16371-9. Diskussion realistischer metaphysischer Interpretationsoptionen.
Bas van Fraassen: Quantum Mechanics, An Empiricist View. Oxford University Press, Oxford 1991, ISBN 0-19-823980-7. (Ausgearbeitete antirealistische Interpretation aus der Position des konstruktiven Empirismus.)
Cord Friebe, Meinard Kuhlmann, Holger Lyre, Paul Näger, Oliver Passon, Manfred Stöckler: Philosophie der Quantenphysik. Einführung und Diskussion der zentralen Begriffe und Problemstellungen der Quantentheorie für Physiker und Philosophen. Springer Spektrum 2015, ISBN 978-3-642-37789-1
R. I. G. Hughes: The structure and interpretation of quantum mechanics. Harvard University Press, Cambridge, Massachusetts 1989, ISBN 0-674-84391-6. (Einführung in den Formalismus und verschiedene Aspekte der Interpretation der Quantenmechanik.)
Gregg Jaeger (2009) Entanglement, Information, and the Interpretation of Quantum Mechanics. Springer, ISBN 978-3-540-92127-1.
Hilary Putnam, A Philosopher Looks at Quantum Mechanics (Again). in: The British Journal for the Philosophy of Science, 56/4 (2005), S. 615–634. doi:10.1093/bjps/axi135 (Ablehnung „kopenhagener“ Interpretationen als bloßen Zurückweisungen eines wissenschaftlichen Realismus und der statistischen Interpretation (Born), Diskussion der wichtigsten verbleibenden realistischen Optionen: spontaner Kollaps (GRW) und Bohm.)
Michael Redhead: Incompleteness, nonlocality and realism: a prolegomenon to the philosophy of quantum mechanics. Clarendon Press, Oxford 1987, ISBN 0-19-824937-3. (Eines der wichtigsten weiterführenden Werke, inklusive einer knappen Darstellung der Theorie.)
Hans Reichenbach, Philosophic Foundations Of Quantum Mechanics. University Of California Press 1944, ISBN 0-486-40459-5.
John Archibald Wheeler, Wojciech Zurek (Herausgeber): Quantum theory and measurement. Princeton University Press, Princeton, NJ 1983, ISBN 0-691-08315-0. (Standard-Handbuch mit den wichtigsten Texten aus der Interpretationsgeschichte, umfangreicher und aktueller als Sexl / Baumann.)
Physik-Nobelpreisträger Theodor W. Hänsch über Interpretationen der Quantenmechanik Interview zur Quantenmechanik bei Drillingsraum.de, 22. Juli 2008
Das Streitgespräch, das Niels Bohr und Erwin Schrödinger am 2. Aug. 1935 über die Deutung der Quantenphänomene und über die Deutung der Quantentheorie führten. (PDF, 473 kB)
Die Quantenmechanik - der Traum, aus dem die Stoffe sind Allgemeinverständliche Übersicht der aktuellen Interpretationen, September 2015

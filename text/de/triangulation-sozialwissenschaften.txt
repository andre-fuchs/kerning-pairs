Triangulation ist eine Forschungsstrategie in der empirischen Sozialforschung, bei der verschiedene Methoden oder Sichtweisen auf das gleiche Phänomen angewendet werden oder verschiedenartige Daten zur Erforschung eines Phänomens herangezogen werden, um mit den Stärken der jeweils einen Vorgehensweise die Schwächen der jeweils anderen auszugleichen. Ziel ist es zumeist, eine höhere Validität der Forschungsergebnisse zu erreichen und systematische Fehler zu verringern. Eine Reihe von Autoren ist jedoch der Ansicht, Triangulation würde lediglich ein reichhaltigeres, aber nicht unbedingt ein valideres Bild der empirischen Realität ermöglichen. Eine Minderheit von Forschern, vorwiegend aus hermeneutischen Forschungstraditionen, lehnt Triangulation aus erkenntnistheoretischen Gründen vollständig ab.
Triangulation kommt heute zumeist in der Qualitativen Sozialforschung zum Einsatz, innerhalb deren Paradigmen über die vergangenen 40 Jahre die größte Entwicklung der Triangulation stattgefunden hat. Ideengeschichtlich ist sie jedoch in der Quantitativen Sozialforschung verankert.
Die Kombination verschiedener Methoden und Daten in der Sozialforschung wurde bereits im 19. Jahrhundert betrieben, beispielsweise in Lenins 1898 erschienenem Die Entwicklung des Kapitalismus in Russland. Derartiges Kombinieren wurde in der gesamten ersten Hälfte des 20. Jahrhunderts — zum Beispiel in der klassischen Studie Die Arbeitslosen von Marienthal — praktiziert, die dafür heute gebräuchliche metaphorische Bezeichnung „Triangulation“ wurde aber erst ab den 1950er Jahren aus der Geodäsie in die Sozialwissenschaften importiert. Zu Beginn der 1960er Jahre waren insbesondere eher quantitativ orientierte Forscher wie Paul Lazarsfeld Verfechter von Methodenkombinationen, obwohl auch qualitativ arbeitende Soziologen wie Howard S. Becker ebenfalls „Belege verschiedenen Typs“ aufgrund deren höherer Glaubwürdigkeit bevorzugten, ohne dies jedoch „Triangulation“ zu nennen. Erst ab Ende der 1960er Jahre gewann Triangulation durch den Aufstieg der Grounded Theory jedoch als explizit verfolgte Forschungsstrategie und in der allgemeinen methodologischen Literatur immer mehr an Bedeutung. Eine typologische Systematisierung verschiedener Formen von Triangulation entstand erst in den 1970er Jahren. Ab Mitte jener Dekade fand die Triangulation Einzug in viele Standardlehrbücher zur empirischen Sozialforschung, ohne dass jedoch systematische methodische Vorgehensweisen gelehrt wurden. Ab Mitte der 1980er Jahre entstanden erste systematische Kritiken der Triangulation, die in Teilen der Forschungsgemeinschaft zur Verschiebung ihrer Legitimationsbegründung abseits üblicher Validitätsbegriffe geführt hat. Im Zuge der seit Beginn des neuen Jahrtausends verstärkt geförderten integrierten Methodenausbildung in den Sozialwissenschaften gewann die Triangulation weiter an Bedeutung. Allerdings haben starke ideologische Gegensätze zwischen quantitativer und qualitativer Sozialforschung bisher einen schnelleren Anstieg der Anwendung von Triangulation verhindert.
Parallel zur Bedeutung qualitativer Methoden in den verschiedenen sozialwissenschaftlichen Disziplinen ist die Triangulation vor allem weit verbreitet in deren Hochburgen wie der Ethnographie; in mehr quantitativ ausgerichteten Disziplinen wie der Volkswirtschaftslehre ist sie dagegen seltener anzutreffen. Disziplinübergreifend ist Triangulation allerdings eher ein Desiderat in Lehrbüchern denn ein in der Praxis verbreitetes Forschungsprogramm, obgleich beispielsweise 2004 in einer Umfrage unter britischen Bildungsforschern 71 % aller Befragten angaben, sie würden auf Triangulation zurückgreifen. Demgegenüber besteht allerdings ein empirischer Befund, dass Triangulation im Bereich der Betriebswirtschaftslehre in den 1990er Jahren im Vergleich zu den 1980er Jahren zurückging. Hinsichtlich der Forschungsfelder ist Triangulation besonders häufig in Krankenpflege-, Gesundheits-, Tourismus- und Bildungsforschung vorzufinden.
Triangulation ist heute, neben der Sequenzierung, bei der qualitative und quantitative Forschungsstrategien nacheinander angewendet werden, und der Hybridisierung, bei der die Vermischung von Methoden kaum mehr analytisch ausgemacht werden kann, ein Kerngebiet der Methodenkombination in den Sozialwissenschaften. Dabei ist allerdings zu beachten, dass aufgrund der Popularität des Begriffes Triangulation keineswegs ein eindeutig umgrenztes Forschungsprogramm mehr ist.
Generell soll Triangulation Forschungsergebnissen eine höhere Plausibilität und Glaubwürdigkeit verleihen. Die Grundidee ist dabei, dass eine Serie verschiedener jeweils fehler- und problembehafteter Messungen oder Analysen in der Aggregation eine validere Analyse hervorbringen würden, indem die Schwächen der einen Vorgehensweise jeweils durch die Stärken der anderen ausgeglichen würden, weil so Fehler, Probleme oder Messungenauigkeiten aufgedeckt würden. Allerdings gehen übereinstimmende Triangulationsergebnisse nicht unbedingt mit einer hohen (externen) Validität einher, stattdessen ist Triangulationskonsensus zwar notwendig, aber nicht hinreichend für hohe Validität. In jüngerer Zeit rücken zudem eine Reihe von Forschern von traditionellen Validitätskonzepten ab und vermuten nunmehr lediglich, dass Triangulation zwar nicht unbedingt validere, aber doch reichhaltigere Ergebnisse erzielen würde. Eine häufig erwähnte Spezialform dieser Begründung ist dabei der Hinweis auf das Problem, Mikro- und Makroebenen theoretisch und empirisch miteinander zu verbinden, was in den Augen mancher Autoren nur durch die Anwendung verschiedener Methoden und Theorien erfolgen könne. Obwohl letztere Forscher mehr in der Tradition des Relativismus und erstere eher einen kritischen Realismus vertreten, finden sich beide Traditionen in dem in der Triangulationsliteratur häufig zitierten Aphorismus von Richard Levins wieder:
Diesen epistemologischen Legitimierungen der Triangulation stehen pragmatischere Begründungen gegenüber, bei denen Forscher auf neue Methoden zurückgreifen, weil die mit den zuvor benutzten Methoden erreichten Vorhersageergebnisse sich als zu schlecht herausgestellt haben.
Norman K. Denzin entwickelte 1970 die bis heute am weitesten verbreitete Legitimation und Typologisierung der Triangulation. Er unterscheidet dabei vier Formen der Triangulation: Datentriangulation, Forschertriangulation, Theorietriangulation und Methodentriangulation.
Bei der Datentriangulation werden Daten aus verschiedenen Quellen oder verschiedenartige Daten aus derselben Quelle verwendet, um so die verschiedenen Biase unterschiedlichen Datenmaterials auszugleichen. Insbesondere wird dabei an die Erhebung von Daten von Personen in unterschiedlichen sozialen Positionen gedacht. In einer Untersuchung zu Sprachkursen können so beispielsweise Schüler, Lehrer und das administrative Personal befragt werden, da jede dieser Quellen vermutlich eine andere Herangehens- und Sichtweise zu den Sprachkursen aufweisen. Alternativ oder in Verbindung mit dieser Vorgehensweise, könnten zum Beispiel experimentelle Daten, Umfragedaten oder aus einer teilnehmenden Beobachtung über die verschiedenen Personengruppen gesammelt werden. Die verschiedenen Daten wiederum können in verschiedenen Formen vorliegen und ausgewertet werden, beispielsweise Interviewdaten als Transkript (in verschiedenen Transkriptionsformen) oder als Video- oder Audiodateien.
Spezielle Formen dieser Art der Triangulation sind die Zeit- und Ortstriangulation, bei der Daten zu verschiedenen Zeiten beziehungsweise an verschiedenen Orten erhoben werden, um so Idiosynkrasien des historischen Kontexts zu eliminieren.
Eine weitere Möglichkeit ist es, dass verschiedene Forscher die Daten analysieren. Die Teilnahme von mehr als einem Forscher kann den (kognitiven) Interessenkonflikt, der besteht, wenn ein und derselbe Forscher Untersuchungsergebnisse theoretisch formuliert und empirisch belegt, entschärfen. Des Weiteren wird angenommen, dass verschiedene Personen unterschiedliche (oft implizite) Theorieansätze verfolgen und somit zugleich eine Theorientriangulation vorgenommen wird. Dies geht bisweilen sogar so weit, dass bewusst Forscher rekrutiert werden, deren sozialer Hintergrund, zum Beispiel ihr Geschlecht oder ihre soziale Klasse, variiert, weil jener als bedeutend für ihren Zugang zu Daten angesehen wird. Schließlich erhofft man sich in der qualitativen Sozialforschung von der Forschertriangulation auch, dass verschiedene Forscher verschiedene Fähigkeiten in der Datenanalyse mitbringen. Besonders häufig wird Forschertriangulation in der qualitativen Sozialforschung bei teilnehmenden Methoden wie der teilnehmenden Beobachtung angewandt, aber auch traditionelle quantitative Methoden wie die Inhaltsanalyse verwenden diese Strategie und validieren Codebücher mit Hilfe der Intercoder-Reliabilität.
Denzin empfiehlt dabei, nicht wie üblich Studierende oder Doktoranden die Kodierungsarbeit durchführen zu lassen, sondern auf erfahrene qualitative Forscher zurückzugreifen.
Die Methodentriangulation ist die am weitesten verbreitete Methode der Triangulation, wenngleich die Verwendung unterschiedlicher Methoden selbstverständlich häufig auch die Verwendung unterschiedlicher Daten und somit Datentriangulation impliziert.  Ende der 1950er Jahre und zu Beginn der 1960er Jahre, als Triangulation noch eher eine Domäne quantitativ-postpositivistischer Forschung insbesondere in der Psychologie war, war diese Art der Triangulation auf die Anwendung verschiedener Messmodelle beziehungsweise Operationalisierungen beschränkt, wobei zunächst lediglich die Reliabilität verschiedener Operationalisierungen geprüft und verbessert werden sollte und später dann auch validere Messungen angestrebt wurden. Heute ist das Feld der Methodentriangulation wesentlich weiter gefasst, wobei nicht nur verschiedene Messmethoden, sondern verschiedene empirische Forschungsmethoden angewandt werden.
Häufig wird bei der Methodentriangulation mit Norman Denzin zwischen einer Triangulation innerhalb einer Methode und zwischen Methoden unterschieden. Bei der Triangulation innerhalb einer Methode wird die gleiche Methode auf verschiedene Art und Weise angewandt. Bei quantitativen Befragungen kann dies beispielsweise durch die Verwendung verschiedener Indikatoren für die Messung des gleichen Konstrukts geschehen; in der qualitativen Forschung kann dies zum Beispiel in ethnographischen Untersuchungen mittels des Bezugs auf mehrere verschiedene Untersuchungsgruppen erfolgen.Bei der Kombination verschiedener Methoden gibt es wiederum zwei grundsätzliche Möglichkeiten: Zum einen können Daten aus verschiedenen Quellen, zum anderen auch die gleichen Daten in einer Methodenkombination mit verschiedenen Methoden ausgewertet werden. Alternativ können die gleichen Daten konvertiert werden, indem meist qualitative Daten durch Kodierungen in quantitative Daten umgewandelt werden.Wählt man eine Methodenkombination, so kann man in Denzins Typologie sowohl innerhalb als auch zwischen Methoden kombinieren. Die Kombination innerhalb von Methoden bedeutet, dass man die gleiche Methode in verschiedenen Arten anwendet, so wie das beispielsweise bei der multidimensionalen Skalierung geschieht. Heute wird jedoch zumeist zwischen Methoden kombiniert, und hierbei ist dies zumeist die Kombination einer oder mehrerer quantitativer Methoden mit einer oder mehreren qualitativen Methoden, in der Tat ist diese Variante der Methodentriangulation mittlerweile so dominant, dass mache Autoren sie als einzige Form der Triangulation definieren. Dabei können qualitative und quantitative Methoden in beiden Richtungen miteinander kombiniert werden. Beginnt man mit einer quantitativen Erhebung, kann man durch die Anwendung statistischer Techniken besondere Fälle, sogenannte Ausreißer, zur näheren Untersuchung mit Hilfe qualitativer Methoden identifizieren oder aber vermeiden, dass bei der Auswahl von Fällen für qualitative Untersuchungen der typische „Eliten-Bias“ durchschlägt. In umgekehrter Richtung kann man mit Hilfe qualitativer Methoden entwickelte Theorien mittels der Entwicklung und Anwendung geeigneter quantitativer Messinstrumente in größeren Populationen überprüfen. Ein besonders häufiges Beispiel für letztere Version ist die Anwendung von quantitativen Surveys in der Folge von qualitativen Interviews.Derartige Methodenkombinationen können jedoch – unabhängig von der jeweiligen ontologischen und epistemologischen Einschätzung der Triangulation an sich – Probleme ergeben, wenn die verwendeten Methoden zueinander widersprüchliche Ontologien implizieren. Dies hat zur Folge, dass die Kombination verschiedener Methoden immer auch zunächst die Entscheidung für ein bestimmtes erkenntnistheoretisches Forschungsparadigma voraussetzt.Schließlich ist bei der Methodenwahl immer zu beachten, dass die gewählten Methoden kongruent mit den jeweils benutzten Theorien sind; Methodenmix sollte nicht zum Selbstzweck werden.
Bei der Theorientriangulation werden verschiedene theoretische Perspektiven auf das gleiche Phänomen beziehungsweise dieselben Daten angewandt. Denzin enumeriert dabei Interaktionismus, Marxismus, Phänomenologie, Feminismus, Semiotik und cultural studies als mögliche theoretische Perspektiven.Diese Form der Triangulation ist die vermutlich am schwersten zu erreichende; manche Autoren denken sogar, Theorientriangulation sei wahrscheinlich unerreichbar.In den 1990er Jahren schlug Valerie Janesick eine fünfte Art der Triangulation, die interdisziplinäre Triangulation, vor. Ähnlich der theoretischen Triangulation werden hier Ansätze verschiedener Fachdisziplinen verwendet, um die Erklärung eines Phänomens zu entwickeln.
Die verschiedenen Arten der Triangulation können selbstverständlich auch untereinander kombiniert werden. Ein besonders bekanntes Beispiel dieser Art innerhalb der Ethnomethodologie ist Cicourels unbegrenzte Triangulation, bei der sowohl Forscher als auch Forschungssubjekte sowie Forschungsassistenten bei der Generierung verschiedenartigen Datenmaterials und dessen Auswertung mitwirken. Dabei werden verschiedenartige Datenformen von Gesprächen zwischen Forschern und Beforschten erstellt, zum Beispiel indem unterschiedliche Transkriptionsarten zur Erzeugung von Daten für eine Analyse der gleichen Gespräche verwendet werden.
Bei der Datentriangulation sind nach Ansicht vieler Autoren Programme zur computergestützten qualitativen Datenanalyse (CAQDAS-Programme) behilflich, weil sie eine Reihe verschiedenartiger Daten organisieren können; bisweilen wird von der Entwicklung solcher Software sogar ein Impuls für eine stärkere Verbreitung von Triangulation erhofft. Dabei ermöglichen diese Programme dem qualitativ arbeitenden Forscher im Hinblick auf Daten- und Methodentriangulation, von ihm kodierte Daten verlustfrei an Statistik-Programme zu übergeben. Die Untersuchung gewänne so an Transparenz und Systematik. Daneben erlauben verschiedene Kollaborationsfunktionen von CAQDAS den systematischen Vergleich der Analysen des gleichen Datenmaterials durch verschiedene Forscher.Generell wird von der Nutzung von Software in der Methodentriangulation eine Steigerung von analytischer Strenge („rigor“) und Reliabilität erwartet; Studien sollen durch den Einsatz von Software „tiefer“ werden und mehr Details aufweisen. Eine Minderheit von Autoren sieht dagegen in der Verwendung von CAQDAS eine Tendenz zur Rigidität qualitativer Sozialforschung, die möglicherweise zur Verschlechterung des Forschungspotentials dieser Methoden führt.Ein Anwendungsbeispiel für die Verwendung von CAQDAS in der Methodentriangulation ist das Extrahieren von Transkriptionsabschnitten, die in gleicher Weise quantitativ kodiert worden sind.
Obwohl Triangulation zunächst intuitiv verlockend erscheint, so ist sie bei näherer Betrachtung doch nicht völlig unproblematisch. Neben der Wahl der Metapher werden vor allem forschungspragmatische und epistemologische Probleme aufgeworfen.
Ein immer wiederkehrender Kritikpunkt ist die Wahl der Metapher (der Begriff Triangulation stammt ja aus der Geodäsie), deren Zweidimensionalität für ein veraltetes epistemologisches Weltbild stünde.
Auf der rein pragmatischen Ebene stellt sich die Frage, wie man mit Triangulationsergebnissen  umgehen soll, die einander weder bestärken noch bereichern, sondern widersprechen. In der Praxis vertrauen Forscher dabei eher durch qualitative Methoden erzielten Ergebnissen, was aber wohl eher der emotionalen Involviertheit der Forscher mit qualitativen Daten denn einer formal-logischen Legitimationsbegründung zu verdanken ist; ein mithin inakzeptables Vorgehen. Eine gut begründete Lösung dieses Problems gibt es jedoch bis heute nicht. Alan Bryman empfiehlt dann auch lapidar, Inkonsistenzen zum Ausgangspunkt neuer Ideen zur Theorieverbesserung zu machen.
Die bei weitem schärfsten Kritiken der Triangulation entstammen jedoch epistemologischen und ontologischen Überlegungen. Besonders hervorzuheben ist dabei der Realismusvorwurf.
Wie alle Methoden der empirischen Sozialforschung hat auch die Triangulation erkenntnistheoretische Prämissen. In diesem Fall ist es ein (naiver) Realismus, der den Befürwortern der Triangulation vor allem von konstruktivistischer Seite vorgeworfen wird, weil Triangulation notwendigerweise die Existenz einer objektiven Realität voraussetze. Manche Autoren, darunter Norman W. H. Blaikie und Yvonna S. Lincoln, glauben daher sogar, dass Triangulation in der Praxis nur innerhalb (post-)positivistischer Ansätze erfolge. Andere Autoren, darunter Clive Seale, weisen diesen Vorwurf dahingehend zurück, dass Triangulation trotz ihrer Affinität zum Realismus auch in anderen epistemologischen Paradigmen verwendet werden kann. Insbesondere ein Pragmatismus Deweyscher Prägung sei dabei ebenfalls als „epistemologischer Partner“ gut geeignet.
Von Vertretern der Postmoderne wird dagegen angemahnt, dass Triangulation verkenne, dass jede Methode eine andere Sicht auf ein Phänomen wirft; sie schlagen daher statt Triangulation Kristallisation in der Methodenkombination vor, bei der eben gerade nicht äquivalente Ergebnisse erzielt werden sollen.
Ungeachtet aller Vor- und Nachteile der Triangulation bleibt jedoch festzustellen, dass sie trotz zahlreicher Befürworter doch vom Gros insbesondere der dem Postmodernismus zuneigenden sozialwissenschaftlichen Forscher zumeist nicht ernsthaft in Erwägung gezogen wird.
Uwe Flick: Triangulation: Eine Einführung. 2. Auflage. VS Verlag, Wiesbaden 2008, ISBN 978-3-531-15666-8.
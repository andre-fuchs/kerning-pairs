Le match AlphaGo - Lee Sedol (titre officiel : Google DeepMind Challenge Match) est un match de cinq parties de go (jouées sans handicap, avec un temps de réflexion usuel en compétition) entre Lee Sedol, joueur professionnel sud-coréen considéré comme le meilleur joueur du monde au milieu des années 2000, et AlphaGo, un programme de go développé par Google DeepMind, qui s'est tenu entre le 9 et le 15 mars 2016 à Séoul. Le gagnant du match devait recevoir un million de dollars.
AlphaGo a gagné toutes les parties sauf la quatrième. Ce match voit la première victoire d'un programme face à un professionnel du plus haut niveau, et a été pour cette raison comparé avec le match d'échecs historique entre Deep Blue et Garry Kasparov en 1997.
Au cours de la rencontre, AlphaGo a fait preuve d'une créativité et d'une précision de lecture et d'évaluation qui ont surpris les meilleurs professionnels et les ont amenés à déclarer devoir repenser certaines de leurs idées sur le go. Lee Sedol a cependant réussi, au cours de la quatrième partie, à découvrir une faiblesse dans le jeu d'AlphaGo, remportant ainsi une victoire qu'il a déclarée être « sans prix ».
Le match a été suivi, surtout en Asie, par plusieurs centaines de millions de spectateurs, suscitant un regain d'intérêt pour le go. Il a provoqué également de nombreuses réactions des spécialistes d'intelligence artificielle qui ont salué une avancée significative des techniques d'apprentissage automatique.
À la suite de ce match, la Hanguk Kiwon (la fédération coréenne de go) a décerné à AlphaGo un titre honorifique de 9e dan (professionnel) – le plus haut grade existant – en reconnaissance du niveau d'excellence atteint par le programme.
Le go est un jeu de stratégie combinatoire abstrait (de la même famille que les échecs ou les dames) opposant deux adversaires qui tentent de contrôler la plus grande part d'une surface quadrillée, le goban, en y déposant à tour de rôle des pierres noires et blanches.
Malgré ses règles simples, c'est un jeu de plateau complexe exigeant, outre des calculs précis, de l'intuition ainsi que de la pensée créative et stratégique. Il a longtemps été considéré comme un défi difficile pour le domaine de l'intelligence artificielle,, demandant en particulier de pouvoir imiter plus d'aspects de la réflexion humaine que pour les échecs. Dès 1965, le mathématicien Irving John Good écrivait :
« Le go par ordinateur ? – Pour programmer un ordinateur jouant de manière raisonnable (et non simplement en respectant les règles), il est nécessaire de formaliser les principes d'une bonne stratégie, ou de développer un système capable d'apprentissage. Ces principes sont plus qualitatifs et mystérieux qu'aux échecs, et dépendent plus de jugements intuitifs. Je pense donc qu'il sera encore plus difficile de programmer un ordinateur pour qu'il joue convenablement au go qu'aux échecs. »
Avant 2006, les progrès avaient été très lents, les meilleurs programmes n'ayant guère plus que le niveau d'un amateur occasionnel, environ 8e kyu. Un premier progrès essentiel fut alors apporté par une méthode de simulation probabiliste, connue sous le nom de méthode de Monte-Carlo ; des améliorations régulières avaient amené en 2015 les meilleurs programmes au niveau de forts amateurs, environ 5e dan,. Cependant, avant AlphaGo, certains chercheurs affirmaient que les ordinateurs ne battraient jamais un professionnel de haut niveau, et Elon Musk, un des premiers investisseurs de DeepMind, rappelait qu'en 2015, les experts du domaine estimaient qu'un succès contre un professionnel demanderait encore au moins une décennie.
Le match AlphaGo contre Lee Sedol est comparable au match d'échecs de 1997 entre Deep Blue et Garry Kasparov : il marque le tournant symbolique où les ordinateurs deviennent meilleurs que les humains dans une activité donnée,. Cependant, AlphaGo est qualitativement différent de DeepBlue, en ce qu'il utilise des réseaux neuronaux, qui créent et font évoluer leurs règles de comportement, par opposition à un programme utilisant des heuristiques figées codées par des humains ; il en résulte d'ailleurs que les programmeurs d'AlphaGo ne sont en général pas capables d'expliquer précisément pourquoi leur programme a choisi tel ou tel coup,.
En octobre 2015, AlphaGo gagna par 5 à 0 un match contre Fan Hui, 2e dan professionnel et champion d'Europe ; il s'agissait de la première victoire d'une intelligence artificielle contre un joueur professionnel, sans handicap et sur un goban 19×19,. Le match et l'existence même d'AlphaGo furent tenus secrets jusqu'à la publication dans Nature, le 27 janvier 2016, d'un article technique sur AlphaGo, détaillant les méthodes utilisées, et donnant les kifu des parties jouées.
La publication de l'article de Nature et l'annonce du match contre Lee Sedol furent abondamment commentées dans les médias, de nombreux observateurs saluant en particulier l'importante avancée pour l'intelligence artificielle constituée par l'utilisation de réseaux neuronaux convolutifs pour l'apprentissage profond,.
Des doutes persistaient cependant quant à la possibilité pour ces méthodes d'atteindre le niveau des meilleurs joueurs humains, certains commentateurs soulignant l'étendue de l'écart entre Fan Hui (2e dan) et Lee Sedol (9e dan),, et estimant qu'en dépit de la performance que constituait cette victoire, les chances d'AlphaGo face à ce dernier étaient infimes. Ainsi Jonathan Schaeffer, spécialiste canadien d'intelligence artificielle ayant en particulier programmé Chinook (programme ayant résolu le jeu de dames américaines), compara AlphaGo à un « enfant prodige » manquant d'expérience, et affirma que « le vrai accomplissement aura lieu quand le programme jouera contre un joueur du plus haut niveau » ; il était alors certain que Lee Sedol gagnerait le match.
Les joueurs professionnels analysèrent les parties jouées contre Fan Hui et découvrirent des faiblesses dans le jeu d'AlphaGo, en particulier un manque de « sens global » (la prise en compte du plateau entier) et de conscience du « potentiel » (l'aji, c'est-à-dire les faiblesses latentes d'une position) qui les amenèrent à penser que Lee Sedol battrait aisément le programme ; lui-même, ayant étudié ces parties, déclara qu'il pourrait perdre l'année suivante, mais qu'il était certain de gagner 5-0 ou 4-1 cette fois-ci ; cependant, avant le match, il était en fait difficile de déterminer les progrès que le programme avait pu accomplir durant ces cinq mois,. Précisant les informations figurant dans l'article de Nature à ce sujet, l'équipe de Google DeepMind, dans une interview donnée à la presse coréenne, expliqua que la base de données initiale du programme ne contenait que des parties de forts amateurs (et donc qu'il ignorait tout du jeu de Lee Sedol), mais que, jouant contre lui-même, il avait accumulé durant ces quelques mois l'équivalent de « mille ans d'expérience humaine » ; après avoir pris connaissance de ces informations, Lee Sedol se montra nettement moins confiant qu'auparavant, déclarant à la veille du match : « ayant appris aujourd'hui comment ses algorithmes sélectionnent les choix possibles, j'ai l'impression qu'AlphaGo peut imiter l'intuition humaine jusqu'à un certain point. ».
AlphaGo est un programme développé par Google DeepMind. Son algorithme utilise une combinaison de techniques générales déjà anciennes comme l'algorithme minimax, de méthodes spécifiques à la programmation du go (une variante de la méthode de Monte-Carlo) et d'une utilisation innovante de réseaux neuronaux, permettant en particulier l'apprentissage automatique à la fois à partir de bases de données et en laissant le programme jouer contre lui-même. AlphaGo fut initialement entraîné à partir d'un ensemble de 160 000 parties jouées sur le serveur KGS par des joueurs classés sur ce serveur entre 6e et 9e dan amateur,. Ayant atteint une certaine compétence (lui permettant en particulier de prévoir les coups de joueurs professionnels dans près de 60 % des cas), il fut ensuite opposé à des copies du même programme, utilisant l'apprentissage par renforcement pour améliorer son jeu.
Le programme ne contient au départ aucune connaissance spécifique sur le go (en dehors des règles et d'un module de calcul des shichō), et il ne dispose en particulier pas d'une « bibliothèque » de coups (contrairement aux programmes d'échecs) ; comme l'expliquait l'un de ses créateurs : 
« Bien que nous ayons programmé cette machine, nous n'avons aucune idée des coups qu'elle va jouer. Ces coups sont un phénomène émergent de son apprentissage. Nous avons seulement créé la base de données et les algorithmes d'apprentissage. Mais les coups que trouve le programme nous échappent, et sont d'ailleurs bien meilleurs que ceux que nous pourrions trouver en tant que joueurs de go. ».
La version d'AlphaGo pour ce match utilisait à peu près la même puissance de calcul que pour le match contre Fan Hui,, laquelle était de 1 202 processeurs et 176 processeurs graphiques.
Lee Sedol est un joueur de go professionnel coréen classé 9e dan. Né en 1983, il commença sa carrière en 1995, devenant 1er dan professionnel à l'âge de 12 ans, et remportant le titre de meilleur joueur de Corée du Sud en 2000. Entre 2003 et 2015, il a gagné 18 titres internationaux, ce qui faisait de lui le meilleur joueur du monde au milieu des années 2000, ; au moment du match, il était encore classé parmi les cinq premiers. Il est un « héros national » de la Corée du Sud, connu pour son style de jeu non conventionnel et créatif, et pour sa force en milieu et fin de partie,. Quelques semaines avant le match, il remporta pour la quatrième fois le Myungin, le plus important des titres coréens.
Les cinq parties du match eurent lieu les 9, 10, 12, 13 et 15 mars 2016, à l'hôtel Four Seasons de Séoul. Chaque partie commençait à 13 heures, heure de Séoul, soit 04:00 UTC.
Les parties utilisaient les règles chinoises avec un komi de 7 points et demi, chaque joueur ayant un temps de réflexion principal de 2 heures, suivi de 3 périodes de byo yomi de 60 secondes,, ; les joueurs jouaient en salle fermée, en présence de trois observateurs officiels, dont Fan Hui, mais aucun problème n'a amené ceux-ci à intervenir durant le match.
Les parties étaient retransmises en temps réel sur YouTube, et commentées en direct en anglais par Michael Redmond (le seul 9e dan professionnel non asiatique) et Chris Garlock (éditeur de l'e-journal de l'AGA),,. Aja Huang, un 6e dan amateur membre de l'équipe de DeepMind, plaçait les pierres sur le goban au nom d'AlphaGo, lequel fonctionnait à l'aide de la Google Cloud Platform, le serveur étant situé aux États-Unis.
Avant le match, l'équipe de DeepMind avait convenu d'utiliser une version figée d'AlphaGo, qui n'apprenait par conséquent rien et ne variait pas sa stratégie d'une partie sur l'autre,.
Le vainqueur du match devait remporter 1 million $US. AlphaGo ayant gagné, Google DeepMind a annoncé que le prix serait versé à des associations caritatives, dont l'Unicef, ainsi qu'à des organisations de go,. Lee Sedol reçut 170 000 $ (150 000 $ pour avoir joué les cinq parties, et 20 000 $ pour chaque partie gagnée),.
Dès la première partie, Cho Hanseung (professionnel coréen 9e dan) et Michael Redmond observèrent que le jeu d'AlphaGo s'était beaucoup amélioré depuis son match d'octobre 2015 contre Fan Hui,. Il devint rapidement clair qu'il était au moins de la force des meilleurs joueurs humains, Nie Weiping (célèbre 9e dan chinois) estimant par exemple qu'il était « 6e ou 7e dan professionnel dans le fuseki, et 13e à 15e dan ensuite », et Lee Sedol déclarant après avoir perdu les deux premières parties : « Hier, j'ai été surpris, mais aujourd'hui, je le suis plus encore - j'en reste sans voix ». Après la troisième partie, l'espoir que Lee Sedol gagne ne serait-ce qu'une partie sembla abandonner certains commentateurs, Ke Jie, le meilleur joueur chinois actuel, commençant lui-même à douter d'avoir une chance contre AlphaGo. Finalement, les deux dernières parties laissèrent apercevoir quelques failles dans le jeu du programme, que Demis Hassabis, fondateur et vice-président de DeepMind, déclara devoir être analysées de manière détaillée ; il semble en particulier ne pas « connaître » certains tesujis classiques, et commettre ainsi parfois des erreurs tactiques ; dans la quatrième partie, après un coup brillant et inattendu de Lee Sedol, son jeu se dégrada complètement, et il fut contraint à l'abandon. Néanmoins, même si Lee Sedol a affirmé après le match avoir été vaincu psychologiquement, mais pas forcément techniquement, le programme a fait preuve d'une créativité qui a surpris les meilleurs joueurs (par exemple en jouant le coup 37 de la deuxième partie) et, à plusieurs reprises, a joué des coups allant contre la théorie établie, mais qui se sont révélés efficaces, amenant de nombreux professionnels à s'enthousiasmer pour sa technique,, et, à commencer par Lee Sedol, à déclarer qu'ils allaient devoir modifier certaines de leurs idées sur le jeu. Par ailleurs, certaines des caractéristiques du jeu d'AlphaGo ont dérouté les commentateurs : comme il ne se soucie que de probabilités de victoire, et non d'écart territorial, il lui arrive, lorsqu'il se sait en avance, de jouer des coups visiblement faibles, mais ne mettant pas sa victoire en péril, ce qui a pu amener à le sous-estimer dans les deux premières parties.
Au cours du match, certains coups exceptionnels marquèrent les observateurs ; Lee Sedol les commenta dans une série d'articles pour le Dong-a Ilbo :
Dans la première partie, Lee Sedol, ayant les Noirs, et ayant adopté une stratégie d'ouverture inhabituelle, sembla contrôler les combats jusqu'à une sévère invasion d'AlphaGo au coup 102, après laquelle il devint clair qu'il n'avait en fait pas l'avantage ; après quelques imprécisions, il abandonna au coup 186.
Plus précisément, le quatrième coup de Lee Sedol (le coup 7) a été décrit par David Ormerod, comme « un coup étrange destiné à tester la force d'AlphaGo dans le fuseki » ; il a estimé finalement que ce coup était une erreur, sanctionnée par AlphaGo de manière « précise et efficace ». La position d'AlphaGo est jugée favorable avant le coup 80, « important, mais moins urgent que 81 », et qui semble redonner l'avantage à Lee Sedol, jusqu'à l'invasion violente et inattendue en 102, après laquelle Lee Sedol joue deux coups « discutables » en 119 et 123, et finalement le « coup perdant » en 129.
Lee Sedol expliqua après le match avoir commis une erreur critique dans l'ouverture, qui l'avait poursuivi toute la partie ; il déclara que la stratégie de la machine dans la première moitié de la partie était « excellente », et qu'elle avait joué un coup qu'aucun humain n'aurait joué, ; après ce coup, il hésita sur son choix de continuation pendant plus de dix minutes.
La deuxième partie débuta par des innovations théoriques que Lee Sedol n'essaya pas de contrer, se cantonnant à un jeu patient et territorial. Mais le coup 37 (un coup de pression traditionnellement « interdit », car donnant trop de points à l'adversaire) surprit tout le monde ; à partir de ce moment, AlphaGo fit preuve d'une flexibilité spectaculaire, échangeant librement les zones d'influence, et après la partie, Lee Sedol déclara que « AlphaGo avait joué de façon presque parfaite » et, dit-il, « dès le début de la partie, je n'ai jamais eu l'impression que je menais »,,.
Michael Redmond déclara que le coup 37 était « créatif » et « unique », et Lee Sedol prit un temps anormalement long pour y répondre. An Young-gil (8p) le décrivit comme « un coup à l'épaule rare et fascinant », mais trouva « exquise » la réponse de Lee Sedol ; bien qu'il ait estimé que le score restait longtemps indécis, il admira particulièrement les coups 151, 157 et 159 d'AlphaGo, qu'il jugea « brillants ». Cette incertitude sur le vainqueur, partagée par plusieurs commentateurs professionnels, ne reflète pas le sentiment de Lee Sedol, ni celui d'AlphaGo : après le match, Demis Hassabis déclara que dès le milieu de la partie, AlphaGo était confiant en sa victoire,.
Particulièrement vers la fin de la partie, AlphaGo joua plusieurs coups anormaux, les professionnels n'arrivant pas à décider s'il s'agissait d'erreurs, de coups faibles ou d'une stratégie globale cachée. Une explication partielle fut alors donnée par un des créateurs du système : la fonction d'évaluation d'AlphaGo repose sur des simulations (utilisant la méthode de Monte-Carlo) et ne maximise pas le territoire (potentiel), mais la probabilité de gagner, ; si AlphaGo estime qu'en perdant des points, il rend sa victoire plus probable, il choisira cette solution. Dans cette partie, le coup 167 semble ainsi être une erreur grossière, mais Lee Sedol déclara que la bataille de ko qu'AlphaGo lui offrait n'était en fait pas jouable, et An Young-gil résuma la situation en déclarant : « Donc, lorsque AlphaGo joue un coup qui nous semble mou, nous pouvons penser que c'est une erreur, mais nous devrions peut-être plutôt le voir comme une déclaration de victoire »,.
Après la deuxième partie, certains joueurs continuaient à douter de la force réelle d'AlphaGo. La troisième partie fut jugée par les commentateurs comme mettant fin au débat. David Ormerod déclara par exemple que « AlphaGo gagna de manière si convaincante qu'il dissipa tous les doutes que les joueurs experts avaient pu avoir sur sa force. En fait, il joua si bien que c'en était presque effrayant ... En forçant AlphaGo à résister à une attaque sévère en milieu hostile, Lee Sedol lui permit de montrer une puissance insoupçonnée jusque-là ... L'attaque de Lee Sedol ne lui rapportait pas assez ... Un des plus grands virtuoses du milieu de partie venait de se voir souffler la vedette  dans l'éclairage cru des pierres noires et blanches, », et An Young-gil (8p) affirma que la partie montrait que « AlphaGo est tout simplement plus fort que tous les joueurs humains connus,. ».
Contrairement à ce qu'avaient craint certains spécialistes de la programmation du go, AlphaGo se montra capable de gérer des batailles de ko complexes (il n'en était pas apparu dans les parties précédentes). Le coup 148 en particulier fut largement commenté : au milieu de la bataille de ko, AlphaGo se montra suffisamment « confiant » de la gagner pour se permettre de jouer un coup important ailleurs.
Lee Sedol, jouant avec les Noirs, choisit la formation connue sous le nom de « fuseki chinois haut », créant une vaste zone d'influence, et obligeant AlphaGo à l'envahir au coup 12. La défense du groupe faible ainsi créé fut jugée exceptionnelle, en particulier le coup 31 de Lee Sedol, bien que naturel (mais que An Young-gil décrivit comme étant peut-être le « coup perdant »), est sanctionné par l'étonnant « saut d'éléphant » en 32, que Lee Sedol dit « n'avoir pas pu imaginer », et après lequel l'attaque semble s'être retournée contre les Noirs ; Andy Jackson (de l'American Go Association) annonça que, selon Kim Myungwan (8p), la partie était déjà décidée au coup 35. Au coup 48, AlphaGo contrôle clairement le combat, forçant Lee Sedol à défendre ses groupes, et se permettant même au coup 58 de relâcher la pression pour esquisser une vaste zone sur le bord sud, que Lee Sedol tentera en vain d'envahir jusqu'à la fin de la partie. La contre-attaque de Lee Sedol aux coups 77 et 79 est efficacement parée par AlphaGo, le coup 90 simplifiant la position, et la séquence de 102 à 112, décrite par An Young-gil comme « sophistiquée », élimine les dernières possibilités de complications. Finalement, après une séquence brillante d'invasion, Lee Sedol déclenche une bataille de ko complexe au coup 131, mais ne réussit pas à pousser le programme à la faute (le coup 148, s'éloignant du combat, montre à quel point AlphaGo contrôle la situation) ; manquant de menaces de ko, épuisé et découragé,, Lee Sedol abandonne au coup 176.
La quatrième partie fut peut-être la plus spectaculaire du match : alors que la position de Lee Sedol semblait désespérée, il réussit à trouver et à exploiter une faille dans le jeu d'AlphaGo. Selon Demis Hassabis, le coup 78, un tesuji rare qu'AlphaGo n'avait pas envisagé (il lui attribuait une probabilité inférieure à une chance sur dix mille) l'amena à jouer la réponse déjà non optimale 79, qu'il estimait pourtant lui donner 70 % de chance de gagner la partie, puis une série de coups incohérents ; ce n'est pourtant qu'au coup 87 que son estimation s'effondra soudain,, ; les coups qui suivirent (jusqu'au coup 101) furent caractérisés par David Ormerod comme typiques des erreurs des programmes s'appuyant sur la méthode de Monte-Carlo,, et dégradèrent suffisamment la position pour que Lee Sedol, bien qu'en manque de temps, maintienne son avance jusqu'à l'abandon d'AlphaGo au coup 181,.
Dans les parties précédentes, AlphaGo avait montré sa maîtrise d'un style calculatoire visant à obtenir de petits avantages dans chaque échange, style connu sous le nom de souba go. Pour tenter de l'obliger à adopter un style plus risqué, Lee Sedol choisit une stratégie appelée amashi, prenant le plus de profit possible en offrant une vaste zone d'influence, et forçant ainsi AlphaGo à attaquer les invasions de cette zone, créant une situation de « tout ou rien » ; Lee Sedol espérait découvrir de cette manière une faiblesse chez un adversaire supérieur dans les situations de négociation, mais qui pourrait s'avérer incapable de trouver dans ce combat quelque chose à négocier.
Les 11 premiers coups furent identiques à ceux de la deuxième partie, mais Lee Sedol changea alors de joseki, pour obliger AlphaGo à défendre immédiatement son groupe. Lee Sedol concrétisa ses territoires de coins et de bord, permettant à AlphaGo de gagner de l'influence sur le bord nord et au centre. Conformément à sa stratégie d’amashi, Lee Sedol envahit ensuite cette zone d'influence avec les coups de 40 à 48, obligeant AlphaGo à l'attaquer par un coup à l'épaule en 47, mais AlphaGo sacrifia quatre pierres (dont 47) pour gagner l'initiative et transformer le centre en territoire apparemment sûr (coups 47 à 69). Lee Sedol testa la réaction d'AlphaGo avec les coups de 72 à 76 sans réussir à provoquer d'erreur ; à ce stade, les commentateurs commençaient à désespérer de ses chances. C'est alors que Lee Sedol joua le coup 78, un « brillant tesuji » que Gu Li déclara même être un « coup divin » auquel il n'aurait jamais pensé. Bien qu'il soit possible de le réfuter, le coup augmente la complexité de la position, ; après deux coups encore plausibles d'AlphaGo (79 et 81), il joua une série de manœuvres incohérentes (de 83 à 101), laissant déchirer le centre sans grande compensation, et dégradant gravement ses chances de gain ; An Young-gil jugea que le coup 105 perdait définitivement la partie, et malgré quelques jolies séquences et la nécessité pour Lee Sedol de jouer chaque coup en moins d'une minute,
AlphaGo abandonna après le coup 180, estimant que ses chances de gain étaient devenues inférieures à 20 %.
An Young-gil conclut que la partie était « un chef d'œuvre de Lee Sedol, qui deviendra presque sûrement une partie célèbre de l'histoire du go »,. Lee Sedol déclara après le match, sous les acclamations du public, que cette victoire était « sans prix », et qu'il n'avait jamais été aussi heureux d'avoir gagné une unique partie ; estimant qu'il était plus facile de gagner avec Blanc, il demanda à jouer la dernière partie avec Noir, dans l'espoir d'une victoire ayant plus de valeur encore.
Après la victoire de Lee Sedol dans la quatrième partie, il paraissait possible qu'il réitère cet exploit, et de fait, AlphaGo commit (selon Demis Hassabis) une « erreur grave » à l'entrée dans le milieu de partie, mais réussit à en limiter les conséquences, puis à gagner une partie devenue serrée à la suite d'un coup un peu trop agressif de Lee Sedol ; cette lutte pour regagner la partie fut décrite par les observateurs de DeepMind comme « l'expérience de jeu la plus hallucinante que nous ayons eu jusque-là, avec une fin de partie incroyablement serrée et tendue ».
Lee Sedol, avec les Noirs, choisit une ouverture analogue à celle de la première partie, puis développa un jeu territorial, utilisant la même stratégie d’amashi que dans la quatrième partie, tandis qu'AlphaGo s'emparait de l'influence centrale. La partie resta équilibrée jusqu'aux coups 48 à 58, où AlphaGo perdit un combat faute d'avoir reconnu à temps un tesuji classique (un sacrifice de déformation connu sous le nom d'« étreinte de pagode »), permettant à Lee Sedol de prendre l'avantage. AlphaGo commença alors à consolider sa zone d'influence, que Lee Sedol choisit d'envahir en 69, mais il regretta cette décision « trop gourmande » après la partie, estimant qu'une simple érosion lui aurait permis de gagner, alors que la contre-attaque d'AlphaGo en 70 avait été « aventureuse, mais justifiée ». Au coup 90, AlphaGo avait regagné l'équilibre, et joua alors une série de coups décrits par David Ormerod comme « inhabituels, mais subtilement impressionnants » qui lui permirent de prendre un léger avantage. Malgré la tentative de Lee Sedol de renverser la situation aux coups 167 et 169 et grâce à des coups jugés « particulièrement efficaces » par An Young-gil en 154, 186 et 194, le programme parvint ensuite à maintenir son avance jusqu'à l'abandon de Lee Sedol au coup 280,.
Des vidéos des parties et de leurs commentaires furent diffusées en direct en coréen, chinois, japonais et anglais. La diffusion en coréen fut assurée par la chaîne de télévision Baduk TV, celle en chinois (avec des commentaires par Gu Li et Ke Jie) le fut par Tencent Holdings et LeEco, avec environ soixante millions de spectateurs pour la première partie. La diffusion en ligne (en temps réel sur YouTube), commentée en direct par Michael Redmond (le seul 9e dan professionnel non asiatique) et Chris Garlock (éditeur de l'e-journal de l'AGA) fut suivie en moyenne par 80 000 internautes, avec un pic de plus de 100 000 visiteurs vers la fin de la première partie. Également en direct (mais commençant une heure après le début de chaque partie), ce commentaire était repris sur le canal officiel YouTube de l'American Go Association par Kim Myungwan (professionnel coréen 8e dan habitant aux États-Unis) et Cho Hyeyeon (9e dan professionnelle coréenne), assistés par Andrew Jackson, ; sur de nombreux autres sites, des commentaires et des discussions se développaient par écrit durant chaque partie. Au total, on estime que plus de trois cents millions de personnes ont assisté à tout ou partie du match, dont 280 millions en Chine.
La victoire d'AlphaGo est un important jalon pour la recherche en intelligence artificielle. Le jeu de go était considéré jusque-là comme un problème difficile d'apprentissage automatique, supposé être hors de portée des méthodes actuelles,,. En 2015, la plupart des experts pensaient qu'il faudrait au moins dix ans pour qu'un programme soit capable de battre des professionnels du plus haut niveau,, et même au début du match, la majorité des observateurs pensaient que Lee Sedol le gagnerait.
Après les succès des ordinateurs contre les meilleurs joueurs humains aux dames (Chinook), aux échecs (Deep Blue) et désormais au go, les jeux de plateau ne peuvent plus servir comme auparavant de repères à la progression de l'intelligence artificielle. Murray Campbell, de l'équipe de Deep Blue, déclara que la victoire d'AlphaGo « marquait la fin d'une époque... les jeux de plateau sont plus ou moins réglés, et il est temps de passer à autre chose » ; dès la fin du match, des chercheurs de DeepMind envisageaient d'ailleurs de se mesurer ensuite à des champions humains de StarCraft 2, ce que Tim Morten, l'un des producteurs du jeu, semblait confirmer fin mars 2016 aux WCS de Shanghai : ce type de jeux, dits à information incomplète (comme le bridge ou le poker) pourrait résister davantage aux méthodes de l'intelligence artificielle.
Comparé à ceux de Deep Blue ou de Watson, les algorithmes d'AlphaGo sont potentiellement plus adaptables à des problèmes variés, et montrent peut-être que la communauté scientifique fait des progrès en direction de l'intelligence artificielle forte. Certains commentateurs pensent que la victoire d'AlphaGo est une bonne occasion de commencer à se préparer à l'impact éventuel qu'auraient sur la société des « machines intelligentes ». En mars 2016, l'informaticien Stuart Russell, spécialiste en IA, déclara ainsi que « les méthodes de l'intelligence artificielle progressent beaucoup plus vite qu'on ne s'y attendait, ce qui rend la question de leur impact à long terme plus urgente [...] ; pour s'assurer que des systèmes de plus en plus puissants restent sous le contrôle des humains, [...] il y a beaucoup de travail à faire. ». Certains scientifiques, comme Stephen Hawking, Elon Musk ou Eliezer Yudkowsky, s'inquiètent de ce qu'une intelligence artificielle capable d'apprentissage pourrait atteindre par elle-même un niveau d'intelligence générale tel que des conséquences sociales inattendues et dramatiques risqueraient d'en résulter, ; d'autres contestent ce point de vue : l'expert en intelligence artificielle Jean-Gabriel Ganascia pense que « des choses telles que le « bon sens » ne pourront peut-être jamais être simulées » et ajoute qu'il ne voit pas « pourquoi nous devrions avoir peur ; au contraire, cela suscite des espoirs dans de nombreux domaines tels que la santé ou l'exploration de l'espace ». Richard Sutton, quant à lui, dit qu'il « ne pense pas que les gens devraient avoir peur... mais qu'il croit vraiment qu'ils devraient s'y intéresser. ».
Le go est un jeu populaire en Corée du Sud, en Chine et au Japon, et ce match a été observé et analysé par des centaines de millions de personnes à travers le monde ; la diffusion de ces parties semble d'ailleurs avoir également provoqué un afflux de nouveaux joueurs, par exemple l’American Go Association signale une importante augmentation de commandes d'équipements.
De nombreux professionnels, à commencer par Lee Sedol, ont déclaré devoir revoir certaines de leurs idées sur le jeu après ce match. Les coups non orthodoxes d'AlphaGo (jugés discutables à première vue par les professionnels, mais qui prennent tout leur sens après coup) ont fait dire à Cho Hyeyeon (9e dan professionnelle coréenne) que « à l'exception des tout meilleurs, tous les joueurs construisent leur style en imitant les professionnels de haut niveau. AlphaGo semble avoir des coups complètement originaux qu'il a créés lui-même ». En mai 2016, une analyse approfondie des parties du match est toujours en cours, mais Michael Redmond déclarait que « ces cinq parties historiques seront sûrement étudiées tout au long des années qui viennent ».
Toby Manning, l'arbitre du match entre AlphaGo et Fan Hui, et Hajin Lee, secrétaire général de la Fédération internationale de go, pensent tous deux qu'à l'avenir, les joueurs de go utiliseront des programmes tels qu'AlphaGo pour comprendre les erreurs commises dans leurs parties et améliorer leur technique.
Après le match, la Hanguk Kiwon (la fédération coréenne de go) a décerné à AlphaGo un titre honorifique de 9e dan (professionnel), « en reconnaissance de son effort sincère pour maîtriser les fondations taoïstes du go et atteindre un niveau proche du territoire de la divinité. ».
Certains des coups innovants d'AlphaGo apparaissent dans plusieurs parties de professionnels jouées depuis ce match. Lee Sedol lui-même semble avoir progressé, gagnant toutes les rencontres qui ont suivi ; dans une interview donnée au Kyunghyang Shinmun en mai 2016, il déclarait : « Ma façon de penser est devenue plus flexible après ma rencontre avec AlphaGo. J'ai réfléchi aux faiblesses de l'intuition humaine, et je pense que ma prédiction du prochain coup est devenu plus précise lorsque je joue au go. ».
Dès avant la rencontre, d'autres professionnels avaient manifesté leur désir de s'opposer à AlphaGo, même si Ke Jie estimait, au vu de ses parties contre Fan Hui, que ce n'était pas un adversaire digne de lui. Après le match, Lee Sedol regrettait de ne pas avoir donné toute sa mesure, et souhaitait une revanche. Mais ce n'est qu'au début de juin 2016 que la perspective d'une nouvelle rencontre se précisait, l'annonce d'un match contre Ke Jie « avant la fin de l'année » étant faite lors du World Amateur Go Championship à Wuxi ; cependant, le 6 juin, Demis Hassabis refusait de confirmer ces informations,. Le 6 novembre 2016, Deep Mind signalait qu'AlphaGo avait fait des progrès significatifs, et, sans rentrer encore dans les détails, Demis Hassabis annonçait officiellement « de nouvelles parties pour le début de 2017 ». Du 23 au 27 mai 2017, un festival intitulé The Future of Go Summit est organisé par Google et l’association chinoise de weiqi à Wuzhen ; la plus récente version d'AlphaGo y affronte Ke Jie dans un match en trois parties, ainsi que d'autres professionnels chinois jouant en consultation. AlphaGo gagne toutes les parties jouées. Après cette rencontre, Google annonce qu'AlphaGo ne jouera plus en compétition.
Avant la publication de l'article de Nature en janvier 2016, plusieurs groupes s'étaient déjà engagés dans l'utilisation de réseaux neuronaux pour la programmation du go, en particulier Facebook avec un programme appelé DarkForest. De nombreux projets, souvent cherchant à améliorer des programmes préexistants, furent lancés en réaction à cet article, alors même que le match contre Lee Sedol était annoncé le plus souvent comme ne laissant aucune chance à AlphaGo ; c'est en particulier le cas de Deep Zen Go, un projet ambitieux s'appuyant sur Zen (l'un des plus forts programmes commerciaux), projet sponsorisé par la compagnie japonaise de télécommunications Dwango, et en partenariat avec une équipe de deep learning de l'université de Tokyo, ainsi qu'avec les développeurs de Ponanza, l'un des meilleurs programmes de shōgi actuel ; bien que n'ayant pas encore rejoint le niveau d'AlphaGo, Deep Zen a défié Cho Chihun (le joueur le plus titré de l'histoire du go japonais) pour un match en trois parties jouées du 20 au 23 novembre 2016. La victoire d'AlphaGo amena d'autres acteurs à vouloir se mesurer à Google, en particulier Baidu, lequel annonça qu'il lancerait un défi à AlphaGo « d'ici la fin de l'année » (2016) ; China Computer Go, l'équipe chinoise de programmation du go, a fait la même annonce, de manière plus précise.
En réaction à ce match, le gouvernement de la Corée du Sud a annoncé le 17 mars 2016 qu'il investirait mille milliards de wons (environ 800 millions d'euros) pour la recherche en intelligence artificielle au cours des cinq prochaines années.
D'autres experts vaincus dans des confrontations hommes-machine se sont vu interviewés à cette occasion : Garry Kasparov (battu par Deep Blue en 1997) a ainsi déclaré que « les ordinateurs excellent dans les calculs parfaits  ; nos cerveaux, dans les généralités, les planifications à long terme et l’application de modèles généraux à des situations nouvelles. Ce contraste produit des affrontements passionnants dans ces courtes fenêtres de temps où les hommes et les machines jouent à force égale, comme ce fut le cas aux échecs il y a vingt ans et, apparemment, au go aujourd’hui. », et, après la première partie, il a envoyé à Lee Sedol un message de condoléances, lui souhaitant de pouvoir gagner les parties suivantes, mais craignant que « l'inscription soit sur le mur ».
Dans un article pour Slate intitulé « Cher Lee Sedol, moi aussi j'ai été humilié par la machine », Ken Jennings, ancien champion de Jeopardy! battu par le programme Watson en 2011, explique que, à sa grande surprise, « perdre contre un ordinateur diabolique a été plutôt bénéfique à sa carrière » : en effet « tout le monde voulait savoir Ce Que Tout Cela Voulait Dire, et Watson était terriblement mauvais en interview » ; mais s'inquiète : « pour l’heure, il s’agit seulement d’une poignée de champions d’échecs, de jeu de go et de «Jeopardy!» qui n’ont plus l’impression qu’on a besoin d'eux et qui ne se sentent plus utiles. Mais qu’est-ce qui arrivera à la société quand il s’agira de millions de personnes ? »
(en) Cet article est partiellement ou en totalité issu de l’article de Wikipédia en anglais intitulé « AlphaGo versus Lee Sedol » (voir la liste des auteurs).
Au début de juin 2016, seuls cinq livres en coréen avaient été publiés sur le match (voir cette photographie de leurs couvertures) ; des traductions en anglais n'en semblaient pas prévues. En janvier 2017, Yuan Zhou (un des meilleurs joueurs américain) a publié une analyse approfondie du match : (en)  AlphaGo vs Lee Sedol. The Match that Changed the World of Go, Slate & Shell  (ISBN 1-932001-77-8).
(en) Analyse du match et des questions de programmation du go comparée à celle des échecs, sur le site de ChessBase.
(en) How the computer beat the go master ([« Comment l'ordinateur a battu le maître de go »]), article du Scientific American.
Chaque partie a été commentée le soir même sur KGS par Motoki Noguchi ; les enregistrements de ces commentaires sont disponibles sans inscription sur le site du serveur (onglet KGS plus).
Diagrammes interactifs des cinq parties, commentées après le match par Motoki Noguchi (7e dan) et Dai Junfu (8e dan), en s'appuyant sur des commentaires professionnels, figurant sur le site de la Revue française de go ; ces analyses sont publiées (avec des commentaires supplémentaires) dans la Revue française de go à partir du numéro 138 (juillet 2016).
Commentaires officiels en direct par Michael Redmond (9e dan professionnel) et Chris Garlock sur le canal YouTube de Google DeepMind :
Ces remarques sur certains aspects cruciaux des cinq parties ont été publiées en coréen dans le Dong-a Ilbo ; elles ont été traduites en anglais sur le blog Baduk in Korea :
Li Zhe, l'un des plus brillants jeunes professionnels chinois, a publié une série d'articles sur le réseau social WeChat :
(en) Après la première partie : la stratégie de Lee Sedol et les faiblesses d'AlphaGo (11 mars 2016) (texte original (zh))
(en) Après la deuxième partie : personne n'aurait pu faire mieux que Lee Sedol (11 mars 2016) (texte original (zh))
En septembre 2016, ces commentaires, dus à Fan Hui, Gu Li et Zhou Ruiyang (en), ont été publiés sur le site de DeepMind ; ils relativisent certaines analyses faites immédiatement après le match, y compris celles de Lee Sedol :
En septembre 2017, DeepMind a produit un documentaire intitulé AlphaGo (en), contenant quelques informations inédites sur les coulisses de la rencontre, et en reprenant sous l’angle humain les moments les plus marquants.
